# 시스템 보안

## 01. 정보시스템의 범위 및 이해

### CPU
***- CPU(Central Processing Unit, 중앙처리장치)***
  - 입력장치로부터 자료를 받아 연산하고 그 결과를 출력장치로 보내는 일련의 과정을 제어 및 조정하는 핵심장치로 사람의 두뇌에 해당

  - 구성 장치
    - ALU(연산장치)
      - 각종 산술연산과 논리연산들을 수행하는 회로
      - 산술연산 : + - x /
      - 논리연산 : AND OR NOT XOR
    - Register(레지스터)
      - CPU 내부의 소규모 데이터나 중간 결과를 일시적으로 기억해 두는 고속의 전용 영역
      - 컴퓨터 기억장치 중 Access 속도가 가장 빠름
    - Control Unit(제어장치)
      - 프로그램 코드(명령어)를 해석하고, 그것을 실행하기 위한 제어 신호들(Control Signals)을 발생시킴
    - 내부 CPU 버스
      - ALU와 레지스터 간의 데이터 이동을 위한 경로
  
  - 레지스터의 종류
    - PC(Program Counter)
      - 다음에 수행할 명령어가 저장된 주기억장치의 번지를 지정
    - MAR(Memory Address Register)
      - 주기억장치에 접근하기 위한 주기억장치의 번지를 기억
    - MBR(Memory Buffer Register)
      - 주기억장치에 입/출력할 자료를 기억하는 레지스터
    - IR(Instruction Register)
      - 주기억장치에서 인출한 명령코드를 기억하는 레지스터
  
  - 실행파일 분석을 위한 레지스터 종류
    - 실행파일이 실행될 때 사용하는 레지스터의 종류는 64비트, 32비트, 16비트 컴퓨터에 따라 다르다.
    - 즉, 16비트 컴퓨터는 BP이고 32비트는 EBP, 64비트는 RBP를 사용한다.
  <table border=1>
    <tr>
      <td>64비트</td>
      <td>32비트</td>
      <td>설명</td>
    </tr>
    <tr>
      <td>RAX</td>
      <td>EAX</td>
      <td>함수의 반환값(Return) 값을 저장하는데 사용된다.</td>
    </tr>
    <tr>
      <td>RBX</td>
      <td>EBX</td>
      <td>메모리 주소를 저장하기 위해서 사용된다.</td>
    </tr>
    <tr>
      <td>RCX</td>
      <td>ECX</td>
      <td>반복문에 카운터 변수로 사용된다.</td>
    </tr>
    <tr>
      <td>RBP</td>
      <td>EBP</td>
      <td>스택의 base를 가리킨다.</td>
    </tr>
    <tr>
      <td>RSP</td>
      <td>ESP</td>
      <td>스택의 Top을 가리킨다.</td>
    </tr>
  </table>

***- 버스 시스템(Bus System)***
  - 버스는 시스템에 많은 장치를 공유하여 데이터, 주소, 제어 정보를 전달하는 전송 라인이다. 한정된 자원이므로 버스를 획득하기 위한 경합이 많이 발생하는 장치기이 때문에 사용하는 방식에 따라
  입출력 성능에 영향을 많이 준다.

  - 버스 종류
    - 데이터 버스(Data Bus)
      - 시스템 컴포넌트 간 처리 데이터를 전송하기 위한 용도
    - 주소 버스(Address Bus)
      - 기억장소의 위치 또는 장치 식별을 지정하기 위한 라인
      - 라인의 비트 수에 따라 접속될 수 있는 장치의 용량이 결정됨
    - 제어 버스(Control Bus)
      - CPU와 기억장치 또는 I/O 장치 사이의 제어 신호를 전송하는 라인
    
***- CPU의 명령 실행 주기(Instruction Cycle)***
  - CPU의 명령 실행 주기는 하나의 명령어 실행이 끝난 후, 다음 명령어의 수행이 시작되어 끝날때까지 걸리는 시간을 말한다.
  즉 한 명령을 수행하는 데 명령 인출, 해독, 피연산자 인출, 실행, 결과 저장 등의 여러 단계를 거쳐야 하는데, 이러한 단계를
  거쳐 한 명령이 실행되고 다시 다음 명령의 인출이 반복되는 주기를 말한다.
  - 인스트럭션 사이클은 패치(fetch), 간접(indirect), 실행(execution) 및 인터럽트(interrupt)로 구성된다.
  인스트럭션 사이클의 실행 주기는 2단계, 4단계, 5단계 사이클로 구분된다.

  - 인스트럭션 실행
  <table border=1>
    <tr>
      <td>단계</td>
      <td>설명</td>
    </tr>
    <tr>
      <td>인출(Instruction Fetch)</td>
      <td>인출단계는 메모리에서 데이터를 로드하여 CPU에 있는 레지스터에 적재하는 과정</td>
    </tr>
    <tr>
      <td>간접(Indirect)</td>
      <td>
      - 메모리를 참조할 때 간접주소 방식을 사용하는 경우에 실행<br/>
      - 간접주소란 CPU가 메모리를 참조했을 때 데이터가 존재하는 것이 아니라 메모리에 주소가 존재하여 메모리 내에서 한 번 더 조회해서 데이터를 얻는 것
      </td>
    </tr>
    <tr>
      <td>실행(Execution)</td>
      <td>명령과 데이터로 CPU가 산술 및 논리연산을 수행하는 것</td>
    </tr>
    <tr>
      <td>인터럽트(Interrupt)</td>
      <td>
      - 컴퓨터 작동 중 예기치 않은 문제가 발생한 경우라도 업무 처리가 계속될 수 있도록 하는 컴퓨터 운영체제의 한 기능으로, 크게 하드웨어 인터럽트와 소프트웨어 인터럽트로 나뉨<br/>
      - SVC 하드웨어 인터럽트 : 기계착오 인터럽트, 외부 인터럽트, 입출력 인터럽트, 프로그램 검사 인터럽트<br/>
      - 소프트웨어 인터럽트 : CPU 내부에서 자신이 실행한 명령이나 CPU의 명령 실행에 관련된 모듈이 변화하는 경우 발생
      </td>
    </tr>
  </table>

### 메모리 시스템
***- 기억장치 계층구조(Memory Hierachy)***
  - 크기, 속도, 가격당 성능에 따라 분류된 기억장치를 계층적으로 구성함으로써 평균 기억장치 액세스 속도는 높이고 가격 대비 성능비도 적절히 유지하기 위한 설계 아키텍처라고 보면 됨

  - 메모리 계층구조의 이유
    - 액세스 속도가 높아질수록 비트당 가격도 높아진다.
    - 용량이 커질수록 비트당 가격은 낮아진다.
    - 용량이 커질수록 액세스 속도는 낮아진다.

  - 기억장치 계층구조
    - 고속의 CPU와 저속의 보조기억장치 사이에 캐시와 주기억장치를 배치하여 성능 차이를 극복하고, 빠르지만 고가인 SDRAM의 사용량을 줄여 가격적인 경쟁력을 확보할 수 있다.

***- 캐시 메모리(Cache Memory)***
  - 캐시 메모리는 CPU와 주기억장치(Memory)의 속도 차이를 극복하기 위해서 CPU와 주기억장치 사이에 존재하는 고속의 버퍼 메모리이다. 이러한 고속의 메모리를 사용하여 CPU가 작업을 빠르게
  처리할 수 있다.

  - 캐시 메모리 정의
    - 중앙처리장치가 읽어 들인 데이터(명령, 프로그램)들로 채워지는 버퍼 형태의 고속 기억장치이다.
  
  - 캐시 메모리 사상(Mapping) 방식
    - 직접사상(Direct Mapping)
      - Main Memory를 여러 구역으로 분할하여 Cache 슬롯과 매핑한다.

      - `책으로 직접 보는게 좋은 파트` `25page`
        - 태그의 크기 : 메모리를 2m 개의 구역으로 나눈 경우 m개의 태그 필요
        - 적재될 캐시의 주소(위치) 결정 방법
          - 방법 1 : (메모리 블록 주소) modulo(캐시 전체 블록 수)
          - 방법 2 : 캐시의 블록 수가 2N개일 경우 메모리 주소의 하위 N 비트
          - Index(색인) : 캐시의 순서 번호(순차적인 주소이기 때문에 별도 공간을 차지하지 않음)
        - 장점 : 매핑 절차가 단순하고 신속하게 처리
        - 단점 : 높은 캐시 미스율(같은 블록에 사상되는 데이터 캐시 적재 시 교체 발생)
        - Valid bit(유효) : 저장 데이터의 유효성 비트
        - Tag(태그) : 맵핑된 메모리 주소의 캐시 식별을 위한 Index bit로 사용되는 하위 비트를 제외한 상위 비트
  
    - 연관사상(Associate Mapping)
      - 주 메모리의 각 블록이 캐시의 어느 슬롯이든 적재 가능하다.

      - `책으로 직접 보는게 좋은 파트` `26page`
        - 장점 : 지역성 높은 접근 시 캐시 적중률 높음
        - 단점 : 구현 하드웨어가 복잡하여 구현 비용 상승

    - 집합 연관사상(Set Associate Mapping)
      - 직접사상/연관사상 절충 방식으로 캐시와 메모리가 M 대 1로 대응한다.

      - `책으로 직접 보는게 좋은 파트` `26page`
        - 장점 : 직접사상과 연관사상의 장점 수용
        - 단점 : 캐시 Fin/Fout 발생 증가, 구현 비용이 많이 듦

***- 캐시 메모리 관리 방식***
  - CPU는 캐시 메모리에 접근하여 연산에 필요한 명령과 데이터를 읽어 들인다. 만약, CPU가 캐시 메모리에 접근할 때 원하는 데이터가 없다면,
  캐시 메모리는 주기억장치에 접근하여 데이터를 캐시 메모리에 올려야 한다. 즉, 캐시 메모리 관리라는 것은 CPU가 원하는 데이터가 캐시 메모리에
  있을 수 있도록 하는 것을 의미한다.

  - 캐시 메모리 인출 방식
    - Demand Fetch : 필요 시 캐시를 인출하는 방식
    - Pre-Fetch : 예상되는 블록을 미리 패치 해 두는 방식

  - 캐시 메모리 교체(Replacement) 알고리즘의 종류
  <table border=1>
    <tr>
      <td>종류</td>
      <td>설명</td>
      <td>특징</td>
    </td>
    <tr>
      <td>Random</td>
      <td>교체될 Page를 임의 선정</td>
      <td>Overhead가 적음</td>
    </td>
    <tr>
      <td>FIFO(First in First Out)</td>
      <td>캐시 내에 오래 있었던 Page 교체</td>
      <td>자주 사용되는 Page가 교체될 우려</td>
    </td>
    <tr>
      <td>LFU(Least Frequently Used)</td>
      <td>사용 횟수가 가장 적은 Page 교체</td>
      <td>최근 적재된 Page가 교체될 우려</td>
    </td>
    <tr>
      <td>LRU(Least Recently Used)</td>
      <td>가장 오랫동안 사용되지 않은 Page 교체</td>
      <td>Time stamping에 의한 overhead 존재</td>
    </td>
    <tr>
      <td>Optimal</td>
      <td>향후 가장 참조되지 않은 Page 교체</td>
      <td>실현 불가능</td>
    </td>
    <tr>
      <td>NUR(Not Used Recently)</td>
      <td>참조 비트와 수정 비트로 미사용 Page 교체</td>
      <td>최근 사용되지 않은 페이지 교체</td>
    </td>
    <tr>
      <td>SCR(Second Chance Replacement)</td>
      <td>최초 참조 비트 1로 셋, 1인 경우 0으로 셋, 0인 경우 교체</td>
      <td>기회를 한 번 더 줌</td>
    </td>
  </table>

  - 페이지 교체 관리 시 문제점
    - Page Falult(페이지 부재)
      - 기억장치에 적재되지 않은 Page를 사용하려 할 때 Page Fault 발생
    - Demand Paging(요구 페이징)
      - 요구될 때에만 Process가 Page를 적재하는 방식
    - Thrashing(스레싱)
      - Page 부재가 너무 빈번하게 발생하여 CPU가 Process 수행보다 Page 교체에 더 많은 시간을 소요하는 비정상적인 현상

  - 페이지 교체 관리 문제 해결 방안
    - Load Control
      - 일정 시간 동안 새로운 프로세서가 생성되는 것을 지연시키고 Suspend Queue에 대기 시켜서 Thrashing 현상을 감소시킴
    - Locality(구역성)
      - 시간과 공간 지역성을 집중적으로 참조함
    - Working Set(워킹셋)
      - 일정 시간 동안 참조되는 페이지 집합(Working Set)을 주기억장치에 유지
    - PFF(Page Fault Frequency)
      - Process의 Page Fault 빈도에 따라 Residence set을 조정
      - PFF가 높으면 Residence set의 크기 증가, 낮으면 감소
  
***- 캐시 메모리 일관성(Cache Coherence)***
  - 캐시 메모리 일관성 유지 방식
    - 멀티프로세서 환경에서 각 프로세서가 캐시를 보유하며 캐시에 로드된 데이터를 변경한 경우 주기억장치의 데이터와 동일하게 유지되는 메커니즘이다.

  - 캐시 불일치 발생 원인
    - `책을 통해서` `28page`
      - Write-through 정책이 사용되는 경우 프로세서 P1이 X 값을 110으로 갱신하면 주기억장치(Cache)의 값이 110으로 갱신되나, P2, P3 캐시는 100으로
      일관성이 깨짐
      - Write-back 정책이 사용되는 경우 Store가 일어나기 전까지 2개의 캐시, 주기억장치가 비 일관성 초래

      - CPU가 캐시와 메모리에 데이터를 기록하는 방식은 Write-through와 Write-back 두 종류가 있다.
      각각의 프로세서가 Write-back 정책을 사용하는 경우 데이터를 Cache에만 기록하고, 차후 메모리에 저장하게 된다.
      이렇게 되면 메모리에 기록하기 전까지는 Cache와 메모리의 값이 서로 다른 상황이 발생하게 된다.

      - Write-through 정책을 사용하더라도 상황은 완전하게 해소되지 않는다.
      프로세서 P1, P2, P3가 메모리에 있는 값을 읽어온 상황이라 가정해 보자. 각각의 캐시에 X의 값이 저장된 상황에서 프로세서 P1이 X값을 110으로 갱신하면 Write-through 정책 
      사용 시 주기억장치의 값이 110으로 갱신된다. 그러나 프로세서 P2, P3의 캐시는 X의 값이 100으로 메인 메모리의 값과 다른 상황이 발생한다.

***- 가상 메모리 시스템***
  - 가상 메모리는 주기억장치의 용량이 너무 적기 때문에 보조기억장치(ex. 디스크)를 마치 주기억장치처럼 사용하여 주기억장치의 공간을 확대하는 기억장치 관리 방법이다.

  - 가상 메모리(Virtual Memory)
    - 물리적 메모리 크기의 한계를 극복하기 위해 실제 물리적 메모리보다 더 큰 용량의 메모리 공간을 제공하는 메모리 관리 기법이다.
    - 가상 메모리를 사용하기 위하여 Virtual Address Space를 사용한다.

  - 가상 메모리 관리 단위
    - 페이지(Page) : 가상 기억장치 상에서 동일한 크기의 최소 논리 분할 단위로 나눈 것
    - 세그먼트(Segment) : 사용자 주소 공간을 용도별로 논리적 단위로 나눈 것
  <table border=1>
    <tr>
      <td>구분</td>
      <td>Paging 기법</td>
      <td>Segmentation 기법</td>
    </tr>
    <tr>
      <td>할당</td>
      <td>고정(Static) 분할</td>
      <td>가변(Dynamic) 분할</td>
    </tr>
    <tr>
      <td>적재</td>
      <td>요구 Page만 일부 적재(On-demand)</td>
      <td>프로그램 전체 적재(On-demand)</td>
    </tr>
    <tr>
      <td>관점</td>
      <td>메모리 관리 측면</td>
      <td>파일 관리 측면</td>
    </tr>
    <tr>
      <td>장점</td>
      <td>
      - 요구 Page만 적재 <br/>
      - 외부 단편화 해결 <br/>
      - 교체시간 최소
      </td>
      <td>
      - 사용자 관점 <br/>
      - 개발/프로그래밍 용이 <br/>
      - 내부 단편화 해결 <br/>
      - 코드, 데이터 공유 용이 <br/>
      </td>
    </tr>
    <tr>
      <td>단점</td>
      <td>
      - 내부 단편화(Fragmentation) 발생 <br/>
      - Thrashing, 잦은 디스크 I/O 유발
      </td>
      <td>
      - 외부 단편화 심각 <br/>
      - 메인 메모리가 커야 함
      </td>
    </tr>
  </table>
      
  - 가상 메모리 관리 정책