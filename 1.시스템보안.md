# 시스템 보안

## 01. 정보시스템의 범위 및 이해

### CPU
***- CPU(Central Processing Unit, 중앙처리장치)***
  - 입력장치로부터 자료를 받아 연산하고 그 결과를 출력장치로 보내는 일련의 과정을 제어 및 조정하는 핵심장치로 사람의 두뇌에 해당

  - 구성 장치
    - ALU(연산장치)
      - 각종 산술연산과 논리연산들을 수행하는 회로
      - 산술연산 : + - x /
      - 논리연산 : AND OR NOT XOR
    - Register(레지스터)
      - CPU 내부의 소규모 데이터나 중간 결과를 일시적으로 기억해 두는 고속의 전용 영역
      - 컴퓨터 기억장치 중 Access 속도가 가장 빠름
    - Control Unit(제어장치)
      - 프로그램 코드(명령어)를 해석하고, 그것을 실행하기 위한 제어 신호들(Control Signals)을 발생시킴
    - 내부 CPU 버스
      - ALU와 레지스터 간의 데이터 이동을 위한 경로
  
  - 레지스터의 종류
    - PC(Program Counter)
      - 다음에 수행할 명령어가 저장된 주기억장치의 번지를 지정
    - MAR(Memory Address Register)
      - 주기억장치에 접근하기 위한 주기억장치의 번지를 기억
    - MBR(Memory Buffer Register)
      - 주기억장치에 입/출력할 자료를 기억하는 레지스터
    - IR(Instruction Register)
      - 주기억장치에서 인출한 명령코드를 기억하는 레지스터
  
  - 실행파일 분석을 위한 레지스터 종류
    - 실행파일이 실행될 때 사용하는 레지스터의 종류는 64비트, 32비트, 16비트 컴퓨터에 따라 다르다.
    - 즉, 16비트 컴퓨터는 BP이고 32비트는 EBP, 64비트는 RBP를 사용한다.
  <table border=1>
    <tr>
      <td>64비트</td>
      <td>32비트</td>
      <td>설명</td>
    </tr>
    <tr>
      <td>RAX</td>
      <td>EAX</td>
      <td>함수의 반환값(Return) 값을 저장하는데 사용된다.</td>
    </tr>
    <tr>
      <td>RBX</td>
      <td>EBX</td>
      <td>메모리 주소를 저장하기 위해서 사용된다.</td>
    </tr>
    <tr>
      <td>RCX</td>
      <td>ECX</td>
      <td>반복문에 카운터 변수로 사용된다.</td>
    </tr>
    <tr>
      <td>RBP</td>
      <td>EBP</td>
      <td>스택의 base를 가리킨다.</td>
    </tr>
    <tr>
      <td>RSP</td>
      <td>ESP</td>
      <td>스택의 Top을 가리킨다.</td>
    </tr>
  </table>

***- 버스 시스템(Bus System)***
  - 버스는 시스템에 많은 장치를 공유하여 데이터, 주소, 제어 정보를 전달하는 전송 라인이다. 한정된 자원이므로 버스를 획득하기 위한 경합이 많이 발생하는 장치기이 때문에 사용하는 방식에 따라
  입출력 성능에 영향을 많이 준다.

  - 버스 종류
    - 데이터 버스(Data Bus)
      - 시스템 컴포넌트 간 처리 데이터를 전송하기 위한 용도
    - 주소 버스(Address Bus)
      - 기억장소의 위치 또는 장치 식별을 지정하기 위한 라인
      - 라인의 비트 수에 따라 접속될 수 있는 장치의 용량이 결정됨
    - 제어 버스(Control Bus)
      - CPU와 기억장치 또는 I/O 장치 사이의 제어 신호를 전송하는 라인
    
***- CPU의 명령 실행 주기(Instruction Cycle)***
  - CPU의 명령 실행 주기는 하나의 명령어 실행이 끝난 후, 다음 명령어의 수행이 시작되어 끝날때까지 걸리는 시간을 말한다.
  즉 한 명령을 수행하는 데 명령 인출, 해독, 피연산자 인출, 실행, 결과 저장 등의 여러 단계를 거쳐야 하는데, 이러한 단계를
  거쳐 한 명령이 실행되고 다시 다음 명령의 인출이 반복되는 주기를 말한다.
  - 인스트럭션 사이클은 패치(fetch), 간접(indirect), 실행(execution) 및 인터럽트(interrupt)로 구성된다.
  인스트럭션 사이클의 실행 주기는 2단계, 4단계, 5단계 사이클로 구분된다.

  - 인스트럭션 실행
  <table border=1>
    <tr>
      <td>단계</td>
      <td>설명</td>
    </tr>
    <tr>
      <td>인출(Instruction Fetch)</td>
      <td>인출단계는 메모리에서 데이터를 로드하여 CPU에 있는 레지스터에 적재하는 과정</td>
    </tr>
    <tr>
      <td>간접(Indirect)</td>
      <td>
      - 메모리를 참조할 때 간접주소 방식을 사용하는 경우에 실행<br/>
      - 간접주소란 CPU가 메모리를 참조했을 때 데이터가 존재하는 것이 아니라 메모리에 주소가 존재하여 메모리 내에서 한 번 더 조회해서 데이터를 얻는 것
      </td>
    </tr>
    <tr>
      <td>실행(Execution)</td>
      <td>명령과 데이터로 CPU가 산술 및 논리연산을 수행하는 것</td>
    </tr>
    <tr>
      <td>인터럽트(Interrupt)</td>
      <td>
      - 컴퓨터 작동 중 예기치 않은 문제가 발생한 경우라도 업무 처리가 계속될 수 있도록 하는 컴퓨터 운영체제의 한 기능으로, 크게 하드웨어 인터럽트와 소프트웨어 인터럽트로 나뉨<br/>
      - SVC 하드웨어 인터럽트 : 기계착오 인터럽트, 외부 인터럽트, 입출력 인터럽트, 프로그램 검사 인터럽트<br/>
      - 소프트웨어 인터럽트 : CPU 내부에서 자신이 실행한 명령이나 CPU의 명령 실행에 관련된 모듈이 변화하는 경우 발생
      </td>
    </tr>
  </table>

### 메모리 시스템
***- 기억장치 계층구조(Memory Hierachy)***
  - 크기, 속도, 가격당 성능에 따라 분류된 기억장치를 계층적으로 구성함으로써 평균 기억장치 액세스 속도는 높이고 가격 대비 성능비도 적절히 유지하기 위한 설계 아키텍처라고 보면 됨

  - 메모리 계층구조의 이유
    - 액세스 속도가 높아질수록 비트당 가격도 높아진다.
    - 용량이 커질수록 비트당 가격은 낮아진다.
    - 용량이 커질수록 액세스 속도는 낮아진다.

  - 기억장치 계층구조
    - 고속의 CPU와 저속의 보조기억장치 사이에 캐시와 주기억장치를 배치하여 성능 차이를 극복하고, 빠르지만 고가인 SDRAM의 사용량을 줄여 가격적인 경쟁력을 확보할 수 있다.

***- 캐시 메모리(Cache Memory)***
  - 캐시 메모리는 CPU와 주기억장치(Memory)의 속도 차이를 극복하기 위해서 CPU와 주기억장치 사이에 존재하는 고속의 버퍼 메모리이다. 이러한 고속의 메모리를 사용하여 CPU가 작업을 빠르게
  처리할 수 있다.

  - 캐시 메모리 정의
    - 중앙처리장치가 읽어 들인 데이터(명령, 프로그램)들로 채워지는 버퍼 형태의 고속 기억장치이다.
  
  - 캐시 메모리 사상(Mapping) 방식
    - 직접사상(Direct Mapping)
      - Main Memory를 여러 구역으로 분할하여 Cache 슬롯과 매핑한다.

      - `책으로 직접 보는게 좋은 파트` `25page`
        - 태그의 크기 : 메모리를 2m 개의 구역으로 나눈 경우 m개의 태그 필요
        - 적재될 캐시의 주소(위치) 결정 방법
          - 방법 1 : (메모리 블록 주소) modulo(캐시 전체 블록 수)
          - 방법 2 : 캐시의 블록 수가 2N개일 경우 메모리 주소의 하위 N 비트
          - Index(색인) : 캐시의 순서 번호(순차적인 주소이기 때문에 별도 공간을 차지하지 않음)
        - 장점 : 매핑 절차가 단순하고 신속하게 처리
        - 단점 : 높은 캐시 미스율(같은 블록에 사상되는 데이터 캐시 적재 시 교체 발생)
        - Valid bit(유효) : 저장 데이터의 유효성 비트
        - Tag(태그) : 맵핑된 메모리 주소의 캐시 식별을 위한 Index bit로 사용되는 하위 비트를 제외한 상위 비트
  
    - 연관사상(Associate Mapping)
      - 주 메모리의 각 블록이 캐시의 어느 슬롯이든 적재 가능하다.

      - `책으로 직접 보는게 좋은 파트` `26page`
        - 장점 : 지역성 높은 접근 시 캐시 적중률 높음
        - 단점 : 구현 하드웨어가 복잡하여 구현 비용 상승

    - 집합 연관사상(Set Associate Mapping)
      - 직접사상/연관사상 절충 방식으로 캐시와 메모리가 M 대 1로 대응한다.

      - `책으로 직접 보는게 좋은 파트` `26page`
        - 장점 : 직접사상과 연관사상의 장점 수용
        - 단점 : 캐시 Fin/Fout 발생 증가, 구현 비용이 많이 듦

***- 캐시 메모리 관리 방식***
  - CPU는 캐시 메모리에 접근하여 연산에 필요한 명령과 데이터를 읽어 들인다. 만약, CPU가 캐시 메모리에 접근할 때 원하는 데이터가 없다면,
  캐시 메모리는 주기억장치에 접근하여 데이터를 캐시 메모리에 올려야 한다. 즉, 캐시 메모리 관리라는 것은 CPU가 원하는 데이터가 캐시 메모리에
  있을 수 있도록 하는 것을 의미한다.

  - 캐시 메모리 인출 방식
    - Demand Fetch : 필요 시 캐시를 인출하는 방식
    - Pre-Fetch : 예상되는 블록을 미리 패치 해 두는 방식

  - 캐시 메모리 교체(Replacement) 알고리즘의 종류
  <table border=1>
    <tr>
      <td>종류</td>
      <td>설명</td>
      <td>특징</td>
    </td>
    <tr>
      <td>Random</td>
      <td>교체될 Page를 임의 선정</td>
      <td>Overhead가 적음</td>
    </td>
    <tr>
      <td>FIFO(First in First Out)</td>
      <td>캐시 내에 오래 있었던 Page 교체</td>
      <td>자주 사용되는 Page가 교체될 우려</td>
    </td>
    <tr>
      <td>LFU(Least Frequently Used)</td>
      <td>사용 횟수가 가장 적은 Page 교체</td>
      <td>최근 적재된 Page가 교체될 우려</td>
    </td>
    <tr>
      <td>LRU(Least Recently Used)</td>
      <td>가장 오랫동안 사용되지 않은 Page 교체</td>
      <td>Time stamping에 의한 overhead 존재</td>
    </td>
    <tr>
      <td>Optimal</td>
      <td>향후 가장 참조되지 않은 Page 교체</td>
      <td>실현 불가능</td>
    </td>
    <tr>
      <td>NUR(Not Used Recently)</td>
      <td>참조 비트와 수정 비트로 미사용 Page 교체</td>
      <td>최근 사용되지 않은 페이지 교체</td>
    </td>
    <tr>
      <td>SCR(Second Chance Replacement)</td>
      <td>최초 참조 비트 1로 셋, 1인 경우 0으로 셋, 0인 경우 교체</td>
      <td>기회를 한 번 더 줌</td>
    </td>
  </table>

  - 페이지 교체 관리 시 문제점
    - Page Falult(페이지 부재)
      - 기억장치에 적재되지 않은 Page를 사용하려 할 때 Page Fault 발생
    - Demand Paging(요구 페이징)
      - 요구될 때에만 Process가 Page를 적재하는 방식
    - Thrashing(스레싱)
      - Page 부재가 너무 빈번하게 발생하여 CPU가 Process 수행보다 Page 교체에 더 많은 시간을 소요하는 비정상적인 현상

  - 페이지 교체 관리 문제 해결 방안
    - Load Control
      - 일정 시간 동안 새로운 프로세서가 생성되는 것을 지연시키고 Suspend Queue에 대기 시켜서 Thrashing 현상을 감소시킴
    - Locality(구역성)
      - 시간과 공간 지역성을 집중적으로 참조함
    - Working Set(워킹셋)
      - 일정 시간 동안 참조되는 페이지 집합(Working Set)을 주기억장치에 유지
    - PFF(Page Fault Frequency)
      - Process의 Page Fault 빈도에 따라 Residence set을 조정
      - PFF가 높으면 Residence set의 크기 증가, 낮으면 감소
  
***- 캐시 메모리 일관성(Cache Coherence)***
  - 캐시 메모리 일관성 유지 방식
    - 멀티프로세서 환경에서 각 프로세서가 캐시를 보유하며 캐시에 로드된 데이터를 변경한 경우 주기억장치의 데이터와 동일하게 유지되는 메커니즘이다.

  - 캐시 불일치 발생 원인
    - `책을 통해서` `28page`
      - Write-through 정책이 사용되는 경우 프로세서 P1이 X 값을 110으로 갱신하면 주기억장치(Cache)의 값이 110으로 갱신되나, P2, P3 캐시는 100으로
      일관성이 깨짐
      - Write-back 정책이 사용되는 경우 Store가 일어나기 전까지 2개의 캐시, 주기억장치가 비 일관성 초래

      - CPU가 캐시와 메모리에 데이터를 기록하는 방식은 Write-through와 Write-back 두 종류가 있다.
      각각의 프로세서가 Write-back 정책을 사용하는 경우 데이터를 Cache에만 기록하고, 차후 메모리에 저장하게 된다.
      이렇게 되면 메모리에 기록하기 전까지는 Cache와 메모리의 값이 서로 다른 상황이 발생하게 된다.

      - Write-through 정책을 사용하더라도 상황은 완전하게 해소되지 않는다.
      프로세서 P1, P2, P3가 메모리에 있는 값을 읽어온 상황이라 가정해 보자. 각각의 캐시에 X의 값이 저장된 상황에서 프로세서 P1이 X값을 110으로 갱신하면 Write-through 정책 
      사용 시 주기억장치의 값이 110으로 갱신된다. 그러나 프로세서 P2, P3의 캐시는 X의 값이 100으로 메인 메모리의 값과 다른 상황이 발생한다.

***- 가상 메모리 시스템***
  - 가상 메모리는 주기억장치의 용량이 너무 적기 때문에 보조기억장치(ex. 디스크)를 마치 주기억장치처럼 사용하여 주기억장치의 공간을 확대하는 기억장치 관리 방법이다.

  - 가상 메모리(Virtual Memory)
    - 물리적 메모리 크기의 한계를 극복하기 위해 실제 물리적 메모리보다 더 큰 용량의 메모리 공간을 제공하는 메모리 관리 기법이다.
    - 가상 메모리를 사용하기 위하여 Virtual Address Space를 사용한다.

  - 가상 메모리 관리 단위
    - 페이지(Page) : 가상 기억장치 상에서 동일한 크기의 최소 논리 분할 단위로 나눈 것
    - 세그먼트(Segment) : 사용자 주소 공간을 용도별로 논리적 단위로 나눈 것
  <table border=1>
    <tr>
      <td>구분</td>
      <td>Paging 기법</td>
      <td>Segmentation 기법</td>
    </tr>
    <tr>
      <td>할당</td>
      <td>고정(Static) 분할</td>
      <td>가변(Dynamic) 분할</td>
    </tr>
    <tr>
      <td>적재</td>
      <td>요구 Page만 일부 적재(On-demand)</td>
      <td>프로그램 전체 적재(On-demand)</td>
    </tr>
    <tr>
      <td>관점</td>
      <td>메모리 관리 측면</td>
      <td>파일 관리 측면</td>
    </tr>
    <tr>
      <td>장점</td>
      <td>
      - 요구 Page만 적재 <br/>
      - 외부 단편화 해결 <br/>
      - 교체시간 최소
      </td>
      <td>
      - 사용자 관점 <br/>
      - 개발/프로그래밍 용이 <br/>
      - 내부 단편화 해결 <br/>
      - 코드, 데이터 공유 용이 <br/>
      </td>
    </tr>
    <tr>
      <td>단점</td>
      <td>
      - 내부 단편화(Fragmentation) 발생 <br/>
      - Thrashing, 잦은 디스크 I/O 유발
      </td>
      <td>
      - 외부 단편화 심각 <br/>
      - 메인 메모리가 커야 함
      </td>
    </tr>
  </table>
      
  - 가상 메모리 관리 정책
  <table border=1>
    <tr>
      <td>종류</td>
      <td>설명</td>
      <td>기법의 유형</td>
    </tr>
    <tr>
      <td>할당 기법(Allocation)</td>
      <td>프로세스에게 할당되는 메모리 블록의 단위를 결정</td>
      <td>고정 할당, 가변 할당, Paging, Segmentation</td>
    </tr>
    <tr>
      <td>호출 기법(Fetch Policy)</td>
      <td>보조기억장치에서 주기억장치로 적재할 시점 결정</td>
      <td>Demand Fetch, Pre Fetch</td>
    </tr>
    <tr>
      <td>배치 기법(Placement)</td>
      <td>요구된 페이지를 주기억장치의 어느 곳에 적재할 것인지를 결정</td>
      <td>First fit, Best fit, Next fit, Worst fit</td>
    </tr>
    <tr>
      <td>교체 기법(Replacement)</td>
      <td>주기억장치 공간 부족 시 교체 대상 결정</td>
      <td>Random, FIFO, LRU, LFU, NUR, SCR, Optimal</td>
    </tr>
  </table>

  - 할당 정책(Allocation Policy)
  <table border=1>
    <tr>
      <td>구분</td>
      <td>종류</td>
      <td>설명</td>
    </tr>
    <tr>
      <td rowspan=2>연속 할당</td>
      <td>고정 분할</td>
      <td>
      - 고정된 크기의 단위로 메모리 할당 <br/>
      - 내부 단편화 발생
      </td>
    </tr>
    <tr>
      <td>가변 분할</td>
      <td>
      - 할당 단위를 요청마다 다른 크기로 할당 <br/>
      - 외부 단편화 발생
      </td>
    </tr>
    <tr>
      <td rowspan=2>비연속 할당</td>
      <td>Paging</td>
      <td>가상 메모리 블록을 페이지 단위 관리, TLB와 MMU, Page Table로 관리</td>
    </tr>
    <tr>
      <td>Segmentation</td>
      <td>가변 크기인 세그먼트로 분할, Segment Table로 관리</td>
    </tr>
  </table>

***- 가상 메모리 관리 기법***
  - Paging 메모리 관리 기법
    - 논리주소의 고정된 페이지(Page)라고 불리는 블록들로 분할 관리하는 기법이다.
    - 각각의 페이지는 물리 메모리의 프레임(Frame)과 맵핑한다.
    - 페이지를 가리키는 논리주소에서 프레임을 가리키는 물리주소로 변환한다.
    - `책으로 보자` `29page`
      - 가상 메모리는 먼저 TLB(Translation Look a side Buffer)라는 메모리에서 가상 기억장치와 주기억장치를 매핑한다.
      TLB는 MMU(Main Memory Unit) 하드웨어 내에 있기 때문에 빠르게 매핑이 가능하다. 하지만 TLB 내에 매핑 정보가 없으면
      Page Table에서 매핑을 수행하고 Real Address와 매핑해서 Main Memory를 참조해야 한다.

      - TLB(Translation Look aside Buffer)
        - 페이지 테이블 접근에 따른 지연 문제를 해결하기 위한 변환 버퍼이다.
        - 가장 최근에 사용된 페이지 테이블 항목을 유지한다.
        - 주기억장치의 Cache Memory와 유사하게 관리된다.

      - MMU(Main Memory Unit)
        - 주기억장치와 캐시의 메모리 주소를 변환하는 역할을 수행한다.
        - 캐시의 통제하에 관리된다.
        - 캐시에 먼저 사용된 후 메모리에 쓰여진다.

  - Segmentation 관리 기법
    - 메모리를 세그먼트 세트로 나눠 관리하는 방식이다.
    - 세그먼트는 해당 세그먼트의 시작 주소인 베이스 어드레스(Base Address)와 세그먼트의 크기를 지정하는 길이 값(Length Value)으로 구성된다.
    - 주소 지정은 세그먼트의 베이스 어드레스를 지시하는 Segment Selector와 세그먼트 내의 변위(Offset) 값을 통해 지정한다.
    - 가상 메모리 주소(Virtual Address)는 Segment 번호와 변위 값으로 구성된다.
    - Segment Table에서 Base Segment의 주소를 획득하고 변위 값(Offset)과 결합하여 물리 메모리 주소를 산출한다.
    - `책으로 보자` `30page`
      - Segment는 가변 공간을 할당하기 때문에 계산을 통해서 주소를 매핑한다. Virtual Address는 Segment Table 주소를 매핑하고 Main Memory와 매핑한다.
  
  - Paged Segmentation 기법
    - 페이지들로 세그먼트를 구성하고 세그먼트 표 참조 후 페이지 표를 참조한다.
    - 논리주소는 세그먼트 번호, 페이지 번호, 오프셋으로 구성된다.
    - 외부 단편화는 제거되지만 내부 단편화가 발생할 가능성이 있다.

### I/O 인터페이스
  - 컴퓨터 시스템의 입출력 처리는 주기억장치와 보조기억장치(디스크, 테이프, 플래시 메모리) 간에 입출력을 수행하는 것이다.  
    프로그램에 의한 입출력 관리는 CPU가 연산 도중에 입출력이 필요하면 보조기억장치에서 데이터를 읽어와 주기억장치에 적재하고 CPU는 주기억장치를 참조해서 데이터를 읽어오는 방식이다.  
    이 방법은 입출력을 수행할 때 모든 작업을 CPU가 하기 때문에 CPU는 입출력 동안 다른 작업을 할 수 없다는 문제점을 가진다.  
    인터럽트 입출력 방식은 입출력 인터럽트가 발생되는 소프트웨어 혹은 하드웨어 방식으로 인터럽트를 식별하고 인터럽트 처리 루틴에 의해서 입출력을 수행한다.  
    이 방법은 프로그램에 의한 입출력 보다 CPU의 관여가 적지만, CPU가 입출력을 대기해야 하는 문제가 있다. 그래서 DMA라는 것이 등장했다.  
    DMA는 DMA 제어기를 두어 주기억장치와 입출력장치를 직접 연결하여 CPU의 개입을 최소화한다.  
    입출력 채널은 입출력을 전담하는 전용 하드웨어 카드이다. CPU와 독립적으로 입출력을 수행하고 고속으로 데이터를 전송할 수 있어서 현재 사용하는 컴퓨터는 모두 입출력 채널을 사용한다.

  - 입출력 방법 : CPU 경유 유무에 따라 아래와 같이 분류
    - CPU 경유 : 프로그램에 의한 I/O, 인터럽트에 의한 I/O
    - CPU 비경유 : DMA(Direct Memory Access Controller) Channel I/O

  - 프로그램에 의한 I/O와 인터럽트에 의한 I/O
    - 프로그램에 의한 I/O
      - 컴퓨터 메모리에 기록된 입출력 명령에 의해 수행
      - CPU가 주변장치를 연속 감시하는 Polling 방식
      - 프로세서의 시간을 낭비하고 처리 효율이 낮음
    - 인터럽트에 의한 I/O
      - CPU가 주변 장치들의 데이터 전송을 위한 인터럽트 요청을 감지하면 수행 중이던 작업을 중지하고 데이터 전송을 처리하기 위해 서브루틴으로 분기하여 전송을 수행

***- DMA(Direct Memory Access)***
  - CPU의 개입 없이 I/O 장치와 기억장치 사이의 데이터를 전송하는 접근 방식이다.
  - CPU의 간섭을 배제하고 메모리와 주변장치를 직접 관리하며, 속도가 빠르다.
  - CPU가 DMA로 보내는 제어 정보이다.
    - 데이터 R/W용 메모리의 주소와 제어 신호
    - 메모리 블록은 워드 수를 표시하는 워드 카운트
    - DMA 전송을 위한 시작 제어 신호
  
  - DMA 동작 방식의 종류
    - Cycle Stealing
      - DMA 제어기와 CPU가 버스를 공유. CPU가 버스를 사용하지 않는 사이클에만 접근하고 CPU보다 높은 우선순위를 가짐
    - Burst Mode
      - DMA 제어기가 버스를 점유. 동작 완료 후 버스 해제

***- I.O Processor(Input Output Processor)***
  - 채널에 의한 입출력은 Selector 채널과 Multiplexer 채널이 있다. Selector 채널은 한 번에 한 개씩 데이터를 주기억장치에게 보내는 방식이고, Multiplexer 채널은
  동시에 많은 데이터를 전송할 수 있는 방식이며, 전송 단위에 따라 Byte Multiplexer와 Block Multiplexer 채널이 존재한다.
  - I/O 장치의 다양함과 복잡함 때문에 DMA제어기로는 한계가 있어 별도 전용 처리 기능의 프로세서를 탑재하여 I/O 작업을 처리한다.(I/O Channel 이라고도 함).
  - CPU나 DMA 대신 독립된 입출력 프로세서인 채널이 입출력을 담당한다.
  - 채널이 입출력을 수행하는 동안 CPU는 다른 일을 처리할 수 있으므로 효율성이 향상된다.

  - I/O Processor의 구성요소
    - 프로세서 : I/O 명령어들을 실행할 수 있는 프로세서
    - 지역 기억장치 : 대용량 데이터 블록들을 저장할 수 있는 저장소
    - 버스 인터페이스 : 시스템 버스에 대한 인터페이스
    - 버스 중재회로 : 버스 마스터 및 버스 중재기

  - I/O Processor의 종류
  <table border=1>
    <tr>
      <td>종류</td>
      <td>설명</td>
    </tr>
    <tr>
      <td>Multiplexer Channel</td>
      <td>
      - 저속장치(Printer, Serial 등) 연결 <br/>
      - 시분할 방식으로 Byte 단위 전송
      </td>
    </tr>
    <tr>
      <td>Selector Channel</td>
      <td>
      - 고속장치(Disk, CDROM), 단일 입출력만 가능 <br/>
      - Burst Mode 동작
      </td>
    </tr>
    <tr>
      <td>Block Multiplexer Channel</td>
      <td>Hybrid 모드, 동시에 여러 I/O 처리, 블록 단위</td>
    </tr>
    <tr>
      <td>Byte Multiplexer Channel</td>
      <td>한 개의 채널에 여러 개의 입출력장치를 연결하여 시분할 공유하는 방식, 저속 입출력 방식</td>
    </tr>
  </table>

## 02. 운영체제 구조

### 운영체제(OS, Operating System)의 개요
  - 컴퓨터 시스템의 자원들을 효율적으로 관리하며, 사용자가 컴퓨터를 편리하고 효과적으로 사용할 수 있도록 환경을 제공하는 여러 프로그램의 모임이다.

  - 운영체제의 목적
    - 처리 능력의 향상 : 시간당 작업 처리량(Throughput), 평균 처리시간 개선
    - 신뢰성 향상 : 실패 없이 주어진 기능을 수행할 수 있는 능력
    - 응답시간의 단축 : 사용자가 시스템에 의뢰한 작업의 반응 시간 단축
    - 자원 활용률 향상 : 자원의 공유, 상호배제를 통해 자원 효율적 활용
    - 가용성 향상 : 고장과 오류가 발생해도 운영 영향 최소화

  - 운영체제의 분류 (운영체제의 발달 과정 위에서부터 아래로)
  <table border=1>
    <tr>
      <td>분류</td>
      <td>설명</td>
    </tr>
    <tr>
      <td>Batch Processing System</td>
      <td>
      - 유사한 작업을 모아 일괄처리, 긴 실행 시간 소요 <br/>
      - 하드웨어의 효율적 이용은 가능하나 실시간 처리 미흡
      </td>
    </tr>
  </table>

