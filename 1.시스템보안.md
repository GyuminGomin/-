# 시스템 보안

## 01. 정보시스템의 범위 및 이해

### CPU
***- CPU(Central Processing Unit, 중앙처리장치)***
  - 입력장치로부터 자료를 받아 연산하고 그 결과를 출력장치로 보내는 일련의 과정을 제어 및 조정하는 핵심장치로 사람의 두뇌에 해당

  - 구성 장치
    - ALU(연산장치)
      - 각종 산술연산과 논리연산들을 수행하는 회로
      - 산술연산 : + - x /
      - 논리연산 : AND OR NOT XOR
    - Register(레지스터)
      - CPU 내부의 소규모 데이터나 중간 결과를 일시적으로 기억해 두는 고속의 전용 영역
      - 컴퓨터 기억장치 중 Access 속도가 가장 빠름
    - Control Unit(제어장치)
      - 프로그램 코드(명령어)를 해석하고, 그것을 실행하기 위한 제어 신호들(Control Signals)을 발생시킴
    - 내부 CPU 버스
      - ALU와 레지스터 간의 데이터 이동을 위한 경로
  
  - 레지스터의 종류
    - PC(Program Counter)
      - 다음에 수행할 명령어가 저장된 주기억장치의 번지를 지정
    - MAR(Memory Address Register)
      - 주기억장치에 접근하기 위한 주기억장치의 번지를 기억
    - MBR(Memory Buffer Register)
      - 주기억장치에 입/출력할 자료를 기억하는 레지스터
    - IR(Instruction Register)
      - 주기억장치에서 인출한 명령코드를 기억하는 레지스터
  
  - 실행파일 분석을 위한 레지스터 종류
    - 실행파일이 실행될 때 사용하는 레지스터의 종류는 64비트, 32비트, 16비트 컴퓨터에 따라 다르다.
    - 즉, 16비트 컴퓨터는 BP이고 32비트는 EBP, 64비트는 RBP를 사용한다.
  <table border=1>
    <tr>
      <td>64비트</td>
      <td>32비트</td>
      <td>설명</td>
    </tr>
    <tr>
      <td>RAX</td>
      <td>EAX</td>
      <td>함수의 반환값(Return) 값을 저장하는데 사용된다.</td>
    </tr>
    <tr>
      <td>RBX</td>
      <td>EBX</td>
      <td>메모리 주소를 저장하기 위해서 사용된다.</td>
    </tr>
    <tr>
      <td>RCX</td>
      <td>ECX</td>
      <td>반복문에 카운터 변수로 사용된다.</td>
    </tr>
    <tr>
      <td>RBP</td>
      <td>EBP</td>
      <td>스택의 base를 가리킨다.</td>
    </tr>
    <tr>
      <td>RSP</td>
      <td>ESP</td>
      <td>스택의 Top을 가리킨다.</td>
    </tr>
  </table>

***- 버스 시스템(Bus System)***
  - 버스는 시스템에 많은 장치를 공유하여 데이터, 주소, 제어 정보를 전달하는 전송 라인이다. 한정된 자원이므로 버스를 획득하기 위한 경합이 많이 발생하는 장치기이 때문에 사용하는 방식에 따라
  입출력 성능에 영향을 많이 준다.

  - 버스 종류
    - 데이터 버스(Data Bus)
      - 시스템 컴포넌트 간 처리 데이터를 전송하기 위한 용도
    - 주소 버스(Address Bus)
      - 기억장소의 위치 또는 장치 식별을 지정하기 위한 라인
      - 라인의 비트 수에 따라 접속될 수 있는 장치의 용량이 결정됨
    - 제어 버스(Control Bus)
      - CPU와 기억장치 또는 I/O 장치 사이의 제어 신호를 전송하는 라인
    
***- CPU의 명령 실행 주기(Instruction Cycle)***
  - CPU의 명령 실행 주기는 하나의 명령어 실행이 끝난 후, 다음 명령어의 수행이 시작되어 끝날때까지 걸리는 시간을 말한다.
  즉 한 명령을 수행하는 데 명령 인출, 해독, 피연산자 인출, 실행, 결과 저장 등의 여러 단계를 거쳐야 하는데, 이러한 단계를
  거쳐 한 명령이 실행되고 다시 다음 명령의 인출이 반복되는 주기를 말한다.
  - 인스트럭션 사이클은 패치(fetch), 간접(indirect), 실행(execution) 및 인터럽트(interrupt)로 구성된다.
  인스트럭션 사이클의 실행 주기는 2단계, 4단계, 5단계 사이클로 구분된다.

  - 인스트럭션 실행
  <table border=1>
    <tr>
      <td>단계</td>
      <td>설명</td>
    </tr>
    <tr>
      <td>인출(Instruction Fetch)</td>
      <td>인출단계는 메모리에서 데이터를 로드하여 CPU에 있는 레지스터에 적재하는 과정</td>
    </tr>
    <tr>
      <td>간접(Indirect)</td>
      <td>
      - 메모리를 참조할 때 간접주소 방식을 사용하는 경우에 실행<br/>
      - 간접주소란 CPU가 메모리를 참조했을 때 데이터가 존재하는 것이 아니라 메모리에 주소가 존재하여 메모리 내에서 한 번 더 조회해서 데이터를 얻는 것
      </td>
    </tr>
    <tr>
      <td>실행(Execution)</td>
      <td>명령과 데이터로 CPU가 산술 및 논리연산을 수행하는 것</td>
    </tr>
    <tr>
      <td>인터럽트(Interrupt)</td>
      <td>
      - 컴퓨터 작동 중 예기치 않은 문제가 발생한 경우라도 업무 처리가 계속될 수 있도록 하는 컴퓨터 운영체제의 한 기능으로, 크게 하드웨어 인터럽트와 소프트웨어 인터럽트로 나뉨<br/>
      - SVC 하드웨어 인터럽트 : 기계착오 인터럽트, 외부 인터럽트, 입출력 인터럽트, 프로그램 검사 인터럽트<br/>
      - 소프트웨어 인터럽트 : CPU 내부에서 자신이 실행한 명령이나 CPU의 명령 실행에 관련된 모듈이 변화하는 경우 발생
      </td>
    </tr>
  </table>

### 메모리 시스템
***- 기억장치 계층구조(Memory Hierachy)***
  - 크기, 속도, 가격당 성능에 따라 분류된 기억장치를 계층적으로 구성함으로써 평균 기억장치 액세스 속도는 높이고 가격 대비 성능비도 적절히 유지하기 위한 설계 아키텍처라고 보면 됨

  - 메모리 계층구조의 이유
    - 액세스 속도가 높아질수록 비트당 가격도 높아진다.
    - 용량이 커질수록 비트당 가격은 낮아진다.
    - 용량이 커질수록 액세스 속도는 낮아진다.

  - 기억장치 계층구조
    - 고속의 CPU와 저속의 보조기억장치 사이에 캐시와 주기억장치를 배치하여 성능 차이를 극복하고, 빠르지만 고가인 SDRAM의 사용량을 줄여 가격적인 경쟁력을 확보할 수 있다.

***- 캐시 메모리(Cache Memory)***
  - 캐시 메모리는 CPU와 주기억장치(Memory)의 속도 차이를 극복하기 위해서 CPU와 주기억장치 사이에 존재하는 고속의 버퍼 메모리이다. 이러한 고속의 메모리를 사용하여 CPU가 작업을 빠르게
  처리할 수 있다.

  - 캐시 메모리 정의
    - 중앙처리장치가 읽어 들인 데이터(명령, 프로그램)들로 채워지는 버퍼 형태의 고속 기억장치이다.
  
  - 캐시 메모리 사상(Mapping) 방식
    - 직접사상(Direct Mapping)
      - Main Memory를 여러 구역으로 분할하여 Cache 슬롯과 매핑한다.

      - `책으로 직접 보는게 좋은 파트` `25page`
        - 태그의 크기 : 메모리를 2m 개의 구역으로 나눈 경우 m개의 태그 필요
        - 적재될 캐시의 주소(위치) 결정 방법
          - 방법 1 : (메모리 블록 주소) modulo(캐시 전체 블록 수)
          - 방법 2 : 캐시의 블록 수가 2N개일 경우 메모리 주소의 하위 N 비트
          - Index(색인) : 캐시의 순서 번호(순차적인 주소이기 때문에 별도 공간을 차지하지 않음)
        - 장점 : 매핑 절차가 단순하고 신속하게 처리
        - 단점 : 높은 캐시 미스율(같은 블록에 사상되는 데이터 캐시 적재 시 교체 발생)
        - Valid bit(유효) : 저장 데이터의 유효성 비트
        - Tag(태그) : 맵핑된 메모리 주소의 캐시 식별을 위한 Index bit로 사용되는 하위 비트를 제외한 상위 비트
  
    - 연관사상(Associate Mapping)
      - 주 메모리의 각 블록이 캐시의 어느 슬롯이든 적재 가능하다.

      - `책으로 직접 보는게 좋은 파트` `26page`
        - 장점 : 지역성 높은 접근 시 캐시 적중률 높음
        - 단점 : 구현 하드웨어가 복잡하여 구현 비용 상승

    - 집합 연관사상(Set Associate Mapping)
      - 직접사상/연관사상 절충 방식으로 캐시와 메모리가 M 대 1로 대응한다.

      - `책으로 직접 보는게 좋은 파트` `26page`
        - 장점 : 직접사상과 연관사상의 장점 수용
        - 단점 : 캐시 Fin/Fout 발생 증가, 구현 비용이 많이 듦

***- 캐시 메모리 관리 방식***
  - CPU는 캐시 메모리에 접근하여 연산에 필요한 명령과 데이터를 읽어 들인다. 만약, CPU가 캐시 메모리에 접근할 때 원하는 데이터가 없다면,
  캐시 메모리는 주기억장치에 접근하여 데이터를 캐시 메모리에 올려야 한다. 즉, 캐시 메모리 관리라는 것은 CPU가 원하는 데이터가 캐시 메모리에
  있을 수 있도록 하는 것을 의미한다.

  - 캐시 메모리 인출 방식
    - Demand Fetch : 필요 시 캐시를 인출하는 방식
    - Pre-Fetch : 예상되는 블록을 미리 패치 해 두는 방식

  - 캐시 메모리 교체(Replacement) 알고리즘의 종류
  <table border=1>
    <tr>
      <td>종류</td>
      <td>설명</td>
      <td>특징</td>
    </td>
    <tr>
      <td>Random</td>
      <td>교체될 Page를 임의 선정</td>
      <td>Overhead가 적음</td>
    </td>
    <tr>
      <td>FIFO(First in First Out)</td>
      <td>캐시 내에 오래 있었던 Page 교체</td>
      <td>자주 사용되는 Page가 교체될 우려</td>
    </td>
    <tr>
      <td>LFU(Least Frequently Used)</td>
      <td>사용 횟수가 가장 적은 Page 교체</td>
      <td>최근 적재된 Page가 교체될 우려</td>
    </td>
    <tr>
      <td>LRU(Least Recently Used)</td>
      <td>가장 오랫동안 사용되지 않은 Page 교체</td>
      <td>Time stamping에 의한 overhead 존재</td>
    </td>
    <tr>
      <td>Optimal</td>
      <td>향후 가장 참조되지 않은 Page 교체</td>
      <td>실현 불가능</td>
    </td>
    <tr>
      <td>NUR(Not Used Recently)</td>
      <td>참조 비트와 수정 비트로 미사용 Page 교체</td>
      <td>최근 사용되지 않은 페이지 교체</td>
    </td>
    <tr>
      <td>SCR(Second Chance Replacement)</td>
      <td>최초 참조 비트 1로 셋, 1인 경우 0으로 셋, 0인 경우 교체</td>
      <td>기회를 한 번 더 줌</td>
    </td>
  </table>

  - 페이지 교체 관리 시 문제점
    - Page Falult(페이지 부재)
      - 기억장치에 적재되지 않은 Page를 사용하려 할 때 Page Fault 발생
    - Demand Paging(요구 페이징)
      - 요구될 때에만 Process가 Page를 적재하는 방식
    - Thrashing(스레싱)
      - Page 부재가 너무 빈번하게 발생하여 CPU가 Process 수행보다 Page 교체에 더 많은 시간을 소요하는 비정상적인 현상

  - 페이지 교체 관리 문제 해결 방안
    - Load Control
      - 일정 시간 동안 새로운 프로세서가 생성되는 것을 지연시키고 Suspend Queue에 대기 시켜서 Thrashing 현상을 감소시킴
    - Locality(구역성)
      - 시간과 공간 지역성을 집중적으로 참조함
    - Working Set(워킹셋)
      - 일정 시간 동안 참조되는 페이지 집합(Working Set)을 주기억장치에 유지
    - PFF(Page Fault Frequency)
      - Process의 Page Fault 빈도에 따라 Residence set을 조정
      - PFF가 높으면 Residence set의 크기 증가, 낮으면 감소
  
***- 캐시 메모리 일관성(Cache Coherence)***
  - 캐시 메모리 일관성 유지 방식
    - 멀티프로세서 환경에서 각 프로세서가 캐시를 보유하며 캐시에 로드된 데이터를 변경한 경우 주기억장치의 데이터와 동일하게 유지되는 메커니즘이다.

  - 캐시 불일치 발생 원인
    - `책을 통해서` `28page`
      - Write-through 정책이 사용되는 경우 프로세서 P1이 X 값을 110으로 갱신하면 주기억장치(Cache)의 값이 110으로 갱신되나, P2, P3 캐시는 100으로
      일관성이 깨짐
      - Write-back 정책이 사용되는 경우 Store가 일어나기 전까지 2개의 캐시, 주기억장치가 비 일관성 초래

      - CPU가 캐시와 메모리에 데이터를 기록하는 방식은 Write-through와 Write-back 두 종류가 있다.
      각각의 프로세서가 Write-back 정책을 사용하는 경우 데이터를 Cache에만 기록하고, 차후 메모리에 저장하게 된다.
      이렇게 되면 메모리에 기록하기 전까지는 Cache와 메모리의 값이 서로 다른 상황이 발생하게 된다.

      - Write-through 정책을 사용하더라도 상황은 완전하게 해소되지 않는다.
      프로세서 P1, P2, P3가 메모리에 있는 값을 읽어온 상황이라 가정해 보자. 각각의 캐시에 X의 값이 저장된 상황에서 프로세서 P1이 X값을 110으로 갱신하면 Write-through 정책 
      사용 시 주기억장치의 값이 110으로 갱신된다. 그러나 프로세서 P2, P3의 캐시는 X의 값이 100으로 메인 메모리의 값과 다른 상황이 발생한다.

***- 가상 메모리 시스템***
  - 가상 메모리는 주기억장치의 용량이 너무 적기 때문에 보조기억장치(ex. 디스크)를 마치 주기억장치처럼 사용하여 주기억장치의 공간을 확대하는 기억장치 관리 방법이다.

  - 가상 메모리(Virtual Memory)
    - 물리적 메모리 크기의 한계를 극복하기 위해 실제 물리적 메모리보다 더 큰 용량의 메모리 공간을 제공하는 메모리 관리 기법이다.
    - 가상 메모리를 사용하기 위하여 Virtual Address Space를 사용한다.

  - 가상 메모리 관리 단위
    - 페이지(Page) : 가상 기억장치 상에서 동일한 크기의 최소 논리 분할 단위로 나눈 것
    - 세그먼트(Segment) : 사용자 주소 공간을 용도별로 논리적 단위로 나눈 것
  <table border=1>
    <tr>
      <td>구분</td>
      <td>Paging 기법</td>
      <td>Segmentation 기법</td>
    </tr>
    <tr>
      <td>할당</td>
      <td>고정(Static) 분할</td>
      <td>가변(Dynamic) 분할</td>
    </tr>
    <tr>
      <td>적재</td>
      <td>요구 Page만 일부 적재(On-demand)</td>
      <td>프로그램 전체 적재(On-demand)</td>
    </tr>
    <tr>
      <td>관점</td>
      <td>메모리 관리 측면</td>
      <td>파일 관리 측면</td>
    </tr>
    <tr>
      <td>장점</td>
      <td>
      - 요구 Page만 적재 <br/>
      - 외부 단편화 해결 <br/>
      - 교체시간 최소
      </td>
      <td>
      - 사용자 관점 <br/>
      - 개발/프로그래밍 용이 <br/>
      - 내부 단편화 해결 <br/>
      - 코드, 데이터 공유 용이 <br/>
      </td>
    </tr>
    <tr>
      <td>단점</td>
      <td>
      - 내부 단편화(Fragmentation) 발생 <br/>
      - Thrashing, 잦은 디스크 I/O 유발
      </td>
      <td>
      - 외부 단편화 심각 <br/>
      - 메인 메모리가 커야 함
      </td>
    </tr>
  </table>
      
  - 가상 메모리 관리 정책
  <table border=1>
    <tr>
      <td>종류</td>
      <td>설명</td>
      <td>기법의 유형</td>
    </tr>
    <tr>
      <td>할당 기법(Allocation)</td>
      <td>프로세스에게 할당되는 메모리 블록의 단위를 결정</td>
      <td>고정 할당, 가변 할당, Paging, Segmentation</td>
    </tr>
    <tr>
      <td>호출 기법(Fetch Policy)</td>
      <td>보조기억장치에서 주기억장치로 적재할 시점 결정</td>
      <td>Demand Fetch, Pre Fetch</td>
    </tr>
    <tr>
      <td>배치 기법(Placement)</td>
      <td>요구된 페이지를 주기억장치의 어느 곳에 적재할 것인지를 결정</td>
      <td>First fit, Best fit, Next fit, Worst fit</td>
    </tr>
    <tr>
      <td>교체 기법(Replacement)</td>
      <td>주기억장치 공간 부족 시 교체 대상 결정</td>
      <td>Random, FIFO, LRU, LFU, NUR, SCR, Optimal</td>
    </tr>
  </table>

  - 할당 정책(Allocation Policy)
  <table border=1>
    <tr>
      <td>구분</td>
      <td>종류</td>
      <td>설명</td>
    </tr>
    <tr>
      <td rowspan=2>연속 할당</td>
      <td>고정 분할</td>
      <td>
      - 고정된 크기의 단위로 메모리 할당 <br/>
      - 내부 단편화 발생
      </td>
    </tr>
    <tr>
      <td>가변 분할</td>
      <td>
      - 할당 단위를 요청마다 다른 크기로 할당 <br/>
      - 외부 단편화 발생
      </td>
    </tr>
    <tr>
      <td rowspan=2>비연속 할당</td>
      <td>Paging</td>
      <td>가상 메모리 블록을 페이지 단위 관리, TLB와 MMU, Page Table로 관리</td>
    </tr>
    <tr>
      <td>Segmentation</td>
      <td>가변 크기인 세그먼트로 분할, Segment Table로 관리</td>
    </tr>
  </table>

***- 가상 메모리 관리 기법***
  - Paging 메모리 관리 기법
    - 논리주소의 고정된 페이지(Page)라고 불리는 블록들로 분할 관리하는 기법이다.
    - 각각의 페이지는 물리 메모리의 프레임(Frame)과 맵핑한다.
    - 페이지를 가리키는 논리주소에서 프레임을 가리키는 물리주소로 변환한다.
    - `책으로 보자` `29page`
      - 가상 메모리는 먼저 TLB(Translation Look a side Buffer)라는 메모리에서 가상 기억장치와 주기억장치를 매핑한다.
      TLB는 MMU(Main Memory Unit) 하드웨어 내에 있기 때문에 빠르게 매핑이 가능하다. 하지만 TLB 내에 매핑 정보가 없으면
      Page Table에서 매핑을 수행하고 Real Address와 매핑해서 Main Memory를 참조해야 한다.

      - TLB(Translation Look aside Buffer)
        - 페이지 테이블 접근에 따른 지연 문제를 해결하기 위한 변환 버퍼이다.
        - 가장 최근에 사용된 페이지 테이블 항목을 유지한다.
        - 주기억장치의 Cache Memory와 유사하게 관리된다.

      - MMU(Main Memory Unit)
        - 주기억장치와 캐시의 메모리 주소를 변환하는 역할을 수행한다.
        - 캐시의 통제하에 관리된다.
        - 캐시에 먼저 사용된 후 메모리에 쓰여진다.

  - Segmentation 관리 기법
    - 메모리를 세그먼트 세트로 나눠 관리하는 방식이다.
    - 세그먼트는 해당 세그먼트의 시작 주소인 베이스 어드레스(Base Address)와 세그먼트의 크기를 지정하는 길이 값(Length Value)으로 구성된다.
    - 주소 지정은 세그먼트의 베이스 어드레스를 지시하는 Segment Selector와 세그먼트 내의 변위(Offset) 값을 통해 지정한다.
    - 가상 메모리 주소(Virtual Address)는 Segment 번호와 변위 값으로 구성된다.
    - Segment Table에서 Base Segment의 주소를 획득하고 변위 값(Offset)과 결합하여 물리 메모리 주소를 산출한다.
    - `책으로 보자` `30page`
      - Segment는 가변 공간을 할당하기 때문에 계산을 통해서 주소를 매핑한다. Virtual Address는 Segment Table 주소를 매핑하고 Main Memory와 매핑한다.
  
  - Paged Segmentation 기법
    - 페이지들로 세그먼트를 구성하고 세그먼트 표 참조 후 페이지 표를 참조한다.
    - 논리주소는 세그먼트 번호, 페이지 번호, 오프셋으로 구성된다.
    - 외부 단편화는 제거되지만 내부 단편화가 발생할 가능성이 있다.

### I/O 인터페이스
  - 컴퓨터 시스템의 입출력 처리는 주기억장치와 보조기억장치(디스크, 테이프, 플래시 메모리) 간에 입출력을 수행하는 것이다.  
    프로그램에 의한 입출력 관리는 CPU가 연산 도중에 입출력이 필요하면 보조기억장치에서 데이터를 읽어와 주기억장치에 적재하고 CPU는 주기억장치를 참조해서 데이터를 읽어오는 방식이다.  
    이 방법은 입출력을 수행할 때 모든 작업을 CPU가 하기 때문에 CPU는 입출력 동안 다른 작업을 할 수 없다는 문제점을 가진다.  
    인터럽트 입출력 방식은 입출력 인터럽트가 발생되는 소프트웨어 혹은 하드웨어 방식으로 인터럽트를 식별하고 인터럽트 처리 루틴에 의해서 입출력을 수행한다.  
    이 방법은 프로그램에 의한 입출력 보다 CPU의 관여가 적지만, CPU가 입출력을 대기해야 하는 문제가 있다. 그래서 DMA라는 것이 등장했다.  
    DMA는 DMA 제어기를 두어 주기억장치와 입출력장치를 직접 연결하여 CPU의 개입을 최소화한다.  
    입출력 채널은 입출력을 전담하는 전용 하드웨어 카드이다. CPU와 독립적으로 입출력을 수행하고 고속으로 데이터를 전송할 수 있어서 현재 사용하는 컴퓨터는 모두 입출력 채널을 사용한다.

  - 입출력 방법 : CPU 경유 유무에 따라 아래와 같이 분류
    - CPU 경유 : 프로그램에 의한 I/O, 인터럽트에 의한 I/O
    - CPU 비경유 : DMA(Direct Memory Access Controller) Channel I/O

  - 프로그램에 의한 I/O와 인터럽트에 의한 I/O
    - 프로그램에 의한 I/O
      - 컴퓨터 메모리에 기록된 입출력 명령에 의해 수행
      - CPU가 주변장치를 연속 감시하는 Polling 방식
      - 프로세서의 시간을 낭비하고 처리 효율이 낮음
    - 인터럽트에 의한 I/O
      - CPU가 주변 장치들의 데이터 전송을 위한 인터럽트 요청을 감지하면 수행 중이던 작업을 중지하고 데이터 전송을 처리하기 위해 서브루틴으로 분기하여 전송을 수행

***- DMA(Direct Memory Access)***
  - CPU의 개입 없이 I/O 장치와 기억장치 사이의 데이터를 전송하는 접근 방식이다.
  - CPU의 간섭을 배제하고 메모리와 주변장치를 직접 관리하며, 속도가 빠르다.
  - CPU가 DMA로 보내는 제어 정보이다.
    - 데이터 R/W용 메모리의 주소와 제어 신호
    - 메모리 블록은 워드 수를 표시하는 워드 카운트
    - DMA 전송을 위한 시작 제어 신호
  
  - DMA 동작 방식의 종류
    - Cycle Stealing
      - DMA 제어기와 CPU가 버스를 공유. CPU가 버스를 사용하지 않는 사이클에만 접근하고 CPU보다 높은 우선순위를 가짐
    - Burst Mode
      - DMA 제어기가 버스를 점유. 동작 완료 후 버스 해제

***- I.O Processor(Input Output Processor)***
  - 채널에 의한 입출력은 Selector 채널과 Multiplexer 채널이 있다. Selector 채널은 한 번에 한 개씩 데이터를 주기억장치에게 보내는 방식이고, Multiplexer 채널은
  동시에 많은 데이터를 전송할 수 있는 방식이며, 전송 단위에 따라 Byte Multiplexer와 Block Multiplexer 채널이 존재한다.
  - I/O 장치의 다양함과 복잡함 때문에 DMA제어기로는 한계가 있어 별도 전용 처리 기능의 프로세서를 탑재하여 I/O 작업을 처리한다.(I/O Channel 이라고도 함).
  - CPU나 DMA 대신 독립된 입출력 프로세서인 채널이 입출력을 담당한다.
  - 채널이 입출력을 수행하는 동안 CPU는 다른 일을 처리할 수 있으므로 효율성이 향상된다.

  - I/O Processor의 구성요소
    - 프로세서 : I/O 명령어들을 실행할 수 있는 프로세서
    - 지역 기억장치 : 대용량 데이터 블록들을 저장할 수 있는 저장소
    - 버스 인터페이스 : 시스템 버스에 대한 인터페이스
    - 버스 중재회로 : 버스 마스터 및 버스 중재기

  - I/O Processor의 종류
  <table border=1>
    <tr>
      <td>종류</td>
      <td>설명</td>
    </tr>
    <tr>
      <td>Multiplexer Channel</td>
      <td>
      - 저속장치(Printer, Serial 등) 연결 <br/>
      - 시분할 방식으로 Byte 단위 전송
      </td>
    </tr>
    <tr>
      <td>Selector Channel</td>
      <td>
      - 고속장치(Disk, CDROM), 단일 입출력만 가능 <br/>
      - Burst Mode 동작
      </td>
    </tr>
    <tr>
      <td>Block Multiplexer Channel</td>
      <td>Hybrid 모드, 동시에 여러 I/O 처리, 블록 단위</td>
    </tr>
    <tr>
      <td>Byte Multiplexer Channel</td>
      <td>한 개의 채널에 여러 개의 입출력장치를 연결하여 시분할 공유하는 방식, 저속 입출력 방식</td>
    </tr>
  </table>

## 02. 운영체제 구조

### 운영체제(OS, Operating System)의 개요
  - 컴퓨터 시스템의 자원들을 효율적으로 관리하며, 사용자가 컴퓨터를 편리하고 효과적으로 사용할 수 있도록 환경을 제공하는 여러 프로그램의 모임이다.

  - 운영체제의 목적
    - 처리 능력의 향상 : 시간당 작업 처리량(Throughput), 평균 처리시간 개선
    - 신뢰성 향상 : 실패 없이 주어진 기능을 수행할 수 있는 능력
    - 응답시간의 단축 : 사용자가 시스템에 의뢰한 작업의 반응 시간 단축
    - 자원 활용률 향상 : 자원의 공유, 상호배제를 통해 자원 효율적 활용
    - 가용성 향상 : 고장과 오류가 발생해도 운영 영향 최소화

  - 운영체제의 분류 (운영체제의 발달 과정 위에서부터 아래로)
  <table border=1>
    <tr>
      <td>분류</td>
      <td>설명</td>
    </tr>
    <tr>
      <td>Batch Processing System</td>
      <td>
      - 유사한 작업을 모아 일괄처리, 긴 실행 시간 소요 <br/>
      - 하드웨어의 효율적 이용은 가능하나 실시간 처리 미흡
      </td>
    </tr>
    <tr>
      <td>Multi Programming System</td>
      <td>
      - CPU 가동률 극대화 -> 유휴 시간 최소화 <br/>
      - 작업들을 스케줄링에 의해 수행 <br/>
      - 정교한 메모리 관리 및 스케줄링 필요
      </td>
    </tr>
    <tr>
      <td>Time Sharing / Multi-tasking System</td>
      <td>
      - Multi Programming의 논리적 확장 <br/>
      - 사용자와 시스템 간의 Interactive한 서비스
      </td>
    </tr>
    <tr>
      <td>Multi-Processing System</td>
      <td>
      - 가용성 증대를 위해 여러 개의 CPU로 다중작업을 구현한 시스템
      </td>
    </tr>
    <tr>
      <td>Real-time System</td>
      <td>
      - 시스템 서비스 요청이 발생할 때마다 시간에 제약을 두어 즉시 처리하고 결과를 출력하는 운영체제
      </td>
    </tr>
    <tr>
      <td>Multi-Mode Processing</td>
      <td>
      - 일괄처리, 시분할, 다중처리, 실시간 처리를 한 시스템에서 모두 제공하는 방식
      </td>
    </tr>
    <tr>
      <td>Distributed System</td>
      <td>
      - 독립적 운영체제가 네트워크 등을 이용해 협업
      </td>
    </tr>
  </table>

  - 운영체제의 주요 자원 관리 기능
  <table border="1">
  <tr>
    <td>주요 자원 관리자</td>
    <td>설명</td>
  </tr>
  <tr>
    <td>프로세스 관리</td>
    <td>
      - 프로세스 스케줄링 및 동기화 관리 <br/>
      - 프로세스 생성과 제거, 시작과 정지, 메시지 전달 등의 기능
    </td>
  </tr>
  <tr>
    <td>기억장치 관리</td>
    <td>
      - 프로세스에 메모리 할당 및 회수 관리
    </td>
  </tr>
  <tr>
    <td>주변장치 관리</td>
    <td>
      - 입/출력 장치 스케줄링 및 점유 관리
    </td>
  </tr>
  <tr>
    <td>파일 관리</td>
    <td>
      - 파일의 생성과 삭제, 변경, 유지 등의 관리
    </td>
  </tr>
  </table>

### 프로세스 관리(Process Management)

***- 프로세스(Process)와 스레드(Thread)***
  - 프로세스
    - 레지스터, 스택, 포인터, 실행중인 프로그램, 데이터 등의 집합체
    - 실행중인 프로세스(가장 보편적인 정의)
    - 프로세서에 의해 수행되는 프로그램 단위로 현재 실행 중이거나 곧 실행 가능한 PCB(Process Control Block)를 가진 프로그램

  - 스레드
    - 제어의 흐름을 의미하는 것으로 프로세스에서 실행의 개념만을 분리한 개념
    - 프로세스의 구성을 크게 제어의 흐름 부분(실행 단위)과 실행 환경 부분으로 나눌 때, 스레드는 프로세스의 실행 부분을 담당함으로써 실행의 기본 단위가 됨

  - 스레드와 프로세스의 비교
  <table border=1>
    <tr>
      <td>구분</td>
      <td>스레드</td>
      <td>프로세스</td>
    </tr>
    <tr>
      <td>상호통신</td>
      <td>
      - Library Call <br/>
      - 요청 Thread만 Blocking
      </td>
      <td>
      - System Call <br/>
      - Call 종료 시까지 전체 자원 Blocking
      </td>
    </tr>
    <tr>
      <td>처리방식</td>
      <td>
      - CPU를 이용하는 기본 작업 <br/>
      - 단위로 구분
      </td>
      <td>
      - 자원 할당을 위한 기본 구분 단위
      </td>
    </tr>
    <tr>
      <td>부하</td>
      <td>
      - 프로세스보다 상대적으로 부하 발생이 적음
      </td>
      <td>
      - Context Switching으로 인한 부하 발생 <br/>
      - 프로세스 자원 할당 시 부하 발생
      </td>
    </tr>
  </table>

***-프로세스 상태***
  - 프로세스 상태전이(Process State Transition)
    - 운영체제-프로세스 실행 제어, 프로세스에 대한 정보 유지 등을 담당
    - 프로세스 실행 결정 및 필요한 시스템 자원을 할당하는 과정
    - 프로세스의 상태 변환을 위해 O/S는 작업 스케줄러(Job Scheduler), 프로세스 스케줄러(Process Scheduler) 두 종류의 CPU 스케줄러 사용

  - 프로세스 상태 전이도
    - `책 37page 참고`
    - 프로세스가 실행되면모든 프로세스는 준비상태의 큐(FIFO)로 들어감. 준비 큐의 프로세스는 CPU 스케줄링 알고리즘에 의해 CPU를 점유하게 되고 프로세스를 실행한다.
    CPU에서 실행중인 프로세스가 Time Out이 되면 다시 준비 큐의 뒬 들어가고 CPU를 점유할 때까지 대기함  
    만약 실행 중인 프로세스가 디스크 입출력과 같은 작업이 발생하면 대기 상태가 되고 입출력을 수행한다. 입출력이 완료되면 다시 프로세스는 준비상태로 들어가 대기하게 된다.  
    이렇게 프로세스가 CPU를 점유하는 과정을 프로세스 상태전이라고 함.

  - Active 모드에서의 프로세스 상태 변환
  <table border=1>
    <tr>
      <td colspan=2>상태</td>
      <td>설명</td>
    </tr>
    <tr>
      <td>Admit</td>
      <td>생성->준비</td>
      <td>
      - 준비 큐가 비어있을 때(작업 스케줄러가 담당)
      </td>
    </tr>
    <tr>
      <td>Dispatch</td>
      <td>준비->실행</td>
      <td>
      - 준비 큐에 있는 하나의 프로세스를 선택하여 CPU를 할당 <br/>
      - 프로세스 스케줄러(Process Scheduler)가 담당
      </td>
    </tr>
    <tr>
      <td>Timer Run out</td>
      <td>실행->준비</td>
      <td>
      - CPU를 할당받은 프로세스가 CPU의 제한된 사용시간을 모두 쓴 경우에 발생 <br/>
      - CPU 스케줄링 정책에 따라 우선순위가 높은 프로세스에게 CPU를 양보할 때, 운영 체제 자체의 CPU 서비스 요청 시 전이됨(선점)
      </td>
    </tr>
    <tr>
      <td>Blocked</td>
      <td>실행->슬립(대기)</td>
      <td>
      - CPU를 할당 받은 프로세스가 I/O 요구. 다른 자원요구 등 CPU 이외의 서비스 작업을 원할 때 발생
      </td>
    </tr>
    <tr>
      <td>Wake up</td>
      <td>슬립->준비(대기)</td>
      <td>
      - 대기 중이던 사건(조건)의 처리가 끝났을 때 발생(ex. I/O 작업 완료)
      </td>
    </tr>
    <tr>
      <td>Release</td>
      <td>실행->종료</td>
      <td>
      - 프로세스의 정상/비정상 종료 시 발생
      </td>
    </tr>
  </table>
  
  - 문맥 교환(Context Switching)
    - CPU가 이전의 프로세스 상태를 PCB에 보관하고, 또 다른 프로세스의 정보를 PCB에서 읽어 레지스터에 적재하는 과정
    - 프로세스가 준비 -> 실행, 실행 -> 준비, 실행 -> 대기 등으로 상태 변경될 때 발생
    - 문맥 교환은 인터럽트가 발생하였거나, 실행 중인 프로세스가 CPU 사용을 허가받은 시간(Quantum)을 모두 소모한 경우, I/O 입출력을 위해 대기해야 하는 경우에 발생.  
    선점형 스케줄러를 사용하는 운영체제는 실행 중인 프로세스보다 높은 우선순위를 가진 프로세스가 도착한 경우에도 문맥 교환이 발생  
    2개 이상의 프로그램을 주기억장치에 기억시키고, 중앙처리장치를 번갈아 사용하면서 컴퓨터 자원을 최대로 활용하는 멀티프로그래밍 환경에서 문맥교환 과정이 이루어지며, 병행처리를 수행함.

  - PCB(Process Control Block)
    - 운영체제가 프로세스를 제어하기 위해 정보를 저장해 놓는 곳으로, 프로세스의 상태 정보를 저장하는 구조체
    - 프로세스 상태 관리와 문맥교환(Context Switching)을 위해 필요
    - PCB는 프로세스 생성 시 만들어지며 주기억장치에 유지됨

  - PCB에서 유지되는 정보
    - PID : 프로세스 고유의 번호
    - 포인터 : 다음 실행될 프로세스의 포인터
    - 상태 : 준비, 대기, 실행 등의 상태
    - Register save area : 레지스터 관련 정보
    - Priority : 스케줄링 및 프로세스 우선순위
    - Account : CPU 사용시간, 실제 사용된 시간
    - Memory Pointers : 메모리 관리 정보
    - 입출력 상태 정보
    - 할당된 자원 정보

### CPU 스케줄링(Scheduling) 기법

***- CPU 스케줄링의 개요***
  - 스케줄링의 정의
    - 컴퓨터의 자원을 효율적으로 사용하기 위한 정책을 계획하는 것
    - 특정 자원을 요청하고 있는 프로세스들을 대상으로 CPU 자원을 할당해 주는 순서를 정하는 일

  - 프로세스 스케줄링의 목적
    - CPU 활용 극대화 : CPU의 유휴 시간 최소화
    - 응답시간 단축 : 프로세스 평균 응답 시간 단축
    - 공평한 자원 활용 : 주어진 기간 동안 특정 자원 사용 효율화
    - Multi-tasking 효율화 : 다중 프로세스의 공평한 처리

  - 스케줄러 역할에 의한 구분
    - `39page`
    <table border=1>
    <tr>
      <td>구분</td>
      <td>설명</td>
    </tr>
    <tr>
      <td>장기 스케줄러</td>
      <td>
      - 상위(High level, long term) 스케줄링, 작업 스케줄링(Job 스케줄링) <br/>
      - 어떤 작업이 시스템의 자원들을 차지할 것인지 결정(큐에 적재)
      </td>
    </tr>
    <tr>
      <td>중기 스케줄러</td>
      <td>
      - 어떤 프로세스들이 CPU를 할당받을 것인지 결정 <br/>
      - CPU를 사용하려는 프로세스 간 중재하여 일시 보류 & 재활성화
      </td>
    </tr>
    <tr>
      <td>단기 스케줄러</td>
      <td>
      - 하위 스케줄링, CPU 스케줄링, 프로세스 스케줄링이라고도 함 <br/>
      - CPU 스케줄러인 Dispatcher에 의해 동작됨(프로세스에 CPU 할당)
      </td>
    </tr>
    </table>

  - 스케줄러의 점유 방식에 의한 구분
  <table border=1>
    <tr>
      <td>구분</td>
      <td>선점(Preemptive)</td>
      <td>비선점(Non-preemptive)</td>
    </tr>
    <tr>
      <td>개념</td>
      <td>프로세스가 CPU 점유 중에도 다른 프로세스가 CPU 점유 가능</td>
      <td>프로세스가 CPU를 해제할 때까지 다른 프로세스는 대기</td>
    </tr>
    <tr>
      <td>장점</td>
      <td>
      - 빠른 응답, 모바일, RTOS <br/>
      - 대화식 시분할 적합
      </td>
      <td>
      - 응답 시간 예상 용이 <br/>
      - Batch Process 적합 <br/>
      - 프로세스에 대한 요구를 공정하게 처리
      </td>
    </tr>
    <tr>
      <td>단점</td>
      <td>Overhead 발생(Context-Switching)</td>
      <td>짧은 작업에도 장기간 대기하는 경우가 발생</td>
    </tr>
    <tr>
      <td>스케줄링 기법</td>
      <td>Round-robin, SRT</td>
      <td>FCFS, SJF, HRN</td>
    </tr>
  </table>

***- CPU 스케줄링의 기법***
  - FCFS(First Come First Service)
    - 대기 큐에 도착한 순서에 따라 CPU를 할당
    - 일단 프로세스가 CPU를 차지하면 완료될 때까지 수행
    - 긴 작업이 짧은 작업을 오랫동안 기다리게 할 수 있으며, 중요하지 않은 작업이 중요한 작업을 기다릭 할 가능성이 존재(대화식 Real Time 시스템에는 부적합)
    - 비선점형 스케줄링 기법

  - SJF(Shortest Job First) 스케줄링
    - 기다리고 있는 작업 중에서 수행 시간이 가장 짧다고 판단된 것을 먼저 수행
    - FCFS보다 평균 대기시간을 감소시키는 반면, 큰 작업에 대해서는 FCFS에 비해 대기시간 예측이 어려움
    - 비선점형 스케줄링 기법

  - Round Robin 스케줄링
    - FCFS에 의해 프로세스들이 내보내지며 각 프로세스는 같은 크기의 CPU 시간을 할당
    - CPU 시간이 만료될 때까지 처리를 완료하지 못하면 CPU는 대기중인 다음 프로세스로 넘어가며(Preemptive), 실행 중이던 프로세스는 준비 완료 리스트의 가장 뒤로 보내짐
    - 선점형 스케줄링 기법

  - SRT(Shortest Remaining Time) 스케줄링
    - SJF와 마찬가지로 새로 도착한 프로세스를 포함하여 처리가 완료되는 데까지 가장 짧은 시간이 소요된다고 판단되는 프로세스를 먼저 수행
    - 실행 중인 프로세스라도 남은 처리 시간이 더 짧다고 판단되는 프로세스가 생기면 언제라도 실행중인 프로세스가 선점됨
    - SJF 방식에 선점 방식을 도입하였으며 실시간 시스템에 유리

  - Multi Level Queue
    - 여러 종류의 그룹으로 나누어 여러 개의 큐를 이용하는 스케줄링 기법
    - 그룹화된 작업들은 각각의 준비 큐에 넣어두고 각 큐의 독자적인 스케줄링 알고리즘에 따라 CPU를 할당받는 방법

  - Multi Level Feedback Queue
    - 입출력 위주와 CPU 위주인 프로세스의 특성에 따라 서로 다른 타임 슬라이스를 부여
    - 새로운 프로그램이 들어오면 높은 우선순위를 할당해 주어 단계 1에서 즉시 수행하고, 점차 낮은 우선순위를 부여하며 단계가 n쯤 되는 나중에는 그 작업이 완료될 때까지
    라운드 로빈으로 순환함
    - Multi Level Feedback Queue는 비선점 기법인 우선순위 Queue와 Round Robin을 모두 사용하므로 Hybrid 스케줄링 기법

### 병행성 제어

***- 상호배제(Mutual Exclusion Techniques)***

  - 상호배제 기법의 정의
    - 다수의 프로세스가 동일 자원에 접근 시 무결성을 보장하기 위한 기법
    - 두 개 이상의 프로세스가 공유 자원에 동시에 읽기/쓰기를 못하게 하는 상호배제 메커니즘
    - 임계영역의 개념을 이용하여 두 프로세스가 하나의 공유 자원을 상호 배타적으로 사용하는 기법

***- 임계영역(Critical Section)***
  - 임계영역의 정의
    - 임계영역이란 한순간에 반드시 프로세스 하나만 진입해야 하는데, 프로그램에서 임계 자원을 이용하는 부분으로 공유 자원의 독점을 보장하는 코드 영역을 의미  
    임계 구역은 지정된 시간이 지난 후 종료
    - 병렬컴퓨팅(Parallel Computing)에서 둘 이상의 스레드가 동시에 접근해서는 안 되는 공유 자원(자료 구조 또는 장치)에 접근하는 코드의 일부로도 쓰임.
    - 스레드가 공유자원의 배타적인 사용을 보장받기 위해 임계 구역에 들어가거나 나올 때는 세마포어 같은 동기화 메커니즘이 사용됨.
    - lock()과 unlock()의 차이

  - 임계 영역을 고려한 전형적인 병행프로세스의 구조
<table border=1>
  <tr>
    <td>소스코드 예시</td>
    <td>구조</td>
    <td>설명</td>
  </tr>
  <tr>
    <td rowspan=3>
    - 코드 예시 <br/>
      do { <br/>
      &nbsp;  wait(mutex); // 진입구역 <br/>
      &nbsp;  임계 구역 <br/>
      &nbsp;  signal(mutex); // 출구구역 <br/>
      &nbsp;  나머지 구역 <br/>
      } while()
    </td>
    <td>진입구역(Entry section)</td>
    <td>임계 구역에 진입하기 위해 허용을 요구한 코드 영역</td>
  </tr>
  <tr>
    <td>출구구역(Exit section)</td>
    <td>임계 구역 다음에 나오는 영역으로 임계 구역을 벗어나기 위한 코드 영역</td>
  </tr>
  <tr>
    <td>나머지 구역(Remainder section)</td>
    <td>프로그램의 나머지 코드 영역</td>
  </tr>
</table>

***- 세마포어(Semaphore), 모니터(Monitor)***
  - 세마포어 상호배제 구현 기법
    ```
    wait(S):
      S.count--;
      if (S.count<0) {
        block this process
        place this process in S.queue
      }

      signal[S]:
        S.count++:
        if (S.count=0) {
          remove a process P from S.queue
          place this process P on ready list
        }
    ```
    - 운영체제가 제공하는 자원으로 세마포어 S는 정수 값을 가지느 변수로서 초기화 및 두 개의 연산(P, V 혹은 wait와 signal)으로만 접근 가능한
    특수한 변수를 이용하여 상호배제 구현
    - 세마포어에는 0과 1의 값만을 갖는 이진 세마포어와 0또는 정수 값도 갖는 계수형(Counting) 세마포어가 있음

  - 모니터 상호배제 구현 기법
    - 상호배제 구현을 위해 별도의 프로그램을 작성할 필요가 없으며, 공유 자원을 모니터 내부의 지역변수로 정의하여 상호배제를 구현
    - 모니터는 High Level Language를 지원
    - 지역 변수는 모니터 내의 함수(프로시저)에서만 접근 가능
    - 프로세스는 모니터의 프로시저 호출을 통해 모니터에 진입 가능
    - 언제나 단지 하나의 프로세스만이 모니터 내부에 존재

***- 교착상태(Dead Lock)***
- 교착상태란 하나 또는 둘 이상의 프로세스가 더 이상 계속할 수 없는 어떤 특정 사건을 기다리고 있는 상태를 말함
- 특정 사건이란 자원의 할당과 해제를 의미하며, 둘 이상의 서로 다른 프로세스가 자신이 요구한 자원을 할당받아 점유하고 있으면서 상호 간에 상대방 프로세스에
할당되어 있는 자원으 요구하는 경우를 말함

- 교착상태의 발생조건
  - 상호배제 
    - 프로세서들이 자원을 배타적 점유
    - 다른 프로세서들이 자원 사용 불가
    - 한 번에 한 프로세스만이 자원 사용 가능
  - 점유와 대기
    - 부분 할당, 다른 종류의 자원을 부가적으로 요구하면서, 이미 어떤 자원을 점유하고 있음
  - 비선점
    - 자원들은 그들을 점유하고 있는 프로세스로부터 도중에 해제되지 않음
    - 프로세스들 자신이 점유한 자원을 해제할 수 있음
  - 환형대기
    - 프로세스와 자원들이 원형을 이루며, 각 프로세스는 자신에게 할당된 자원을 가지며, 상대방 프로세스의 자원을 상호 요청하는 경우

***- 교착상태 대응 방법***
- 교착상태 예방 조건
  - 점유와 대기 조건의 부정
    - 각 프로세스는 필요한 자원들을 모두 한꺼번에 요청
  - 비선점 조건의 부정
    - 이미 자원을 가지고 있는 프로세스 -> 자원 할당 요구 있을 시 받아들여지지 않으면 -> 보유 자원 반납
    - 반납 후 필요 자원에 대한 요구 다시 시도
    - 무기한 연기 가능성 존재
  - 환형대기 조건의 부정
    - 모든 프로세스에게 각 자원의 유형별로 할당순서를 부여
    - 실행 중 우선순위의 변동이나 새로운 자원 추가 시 구성이 어려움
  - 상호 배제 조건 부정
    - 상호 배제 조건은 비 공유를 전제
    - 공유 가능한 자원들은 배타적인 접근을 요구하지 않으므로 교착상태가 될 수 없음

- 교착상태 회피(Avoidance)
  - 은행원 알고리즘(Banker's Algorithm)
    - 안전 상태(Safe State)
      - 시스템이 교착상태를 일으키지 않으면서 각 프로세스가 요구한 최대 요구량만큼 필요한 자원을 할당해 줄 수 있는 상태로 안전순서열이 존재하는 상태를 말함
    - 불안전 상태(Unsafe State)
      - 안전순서열이 존재하지 않은 상태, 불안전 상태는 교착상태이기 위한 필요조건, 교착상태는 불안전 상태에서만 발생
    - 안전 상태 개념을 이용하여 교착상태 회피 알고리즘 구성이 가능하며, 현재 가용자원을 프로세스 요청 시 바로 할당해 줄 것인지 기다리게 할 것인지를 결정하는 문제라고 볼 수 있음

- 교착상태 발견(Detection)
  - 교착상태 발견 기법
    - 교착상태 발견 알고리즘
      - 교착상태 발생 여부를 파악하기 위해 시스템의 상태를 검사하기 위한 알고리즘
      - 교착상태의 발생 빈도 수
      - 교착상태가 발생하였을 때 영향을 받는 프로세스의 수
    - 자원 할당 그래프
      - 방향 그래프를 이용해 자원의 할당사항과 요구사항을 나타내는 기법
      - 자원 할당 그래프의 소거법을 이용해 교착상태 감지
      - 실행을 완료할 수 있는 프로세스와 교착상태에 빠진 프로세스를 결정

  - 자원 할당 그래프(Resource Allocation graph)의 예
    - `45page`

- 교착상태 회복(Recovery)
  - 교착상태 회복 기법
    - 프로세스 중지
      - 교착상태 프로세스들을 모두 중지하는 방법
      - 교착상태가 해결될 때까지 한 프로세스씩 중지
      - 희생자 선택의 원칙 : 최소 비용으로 중지시키는 방법을 찾아야 함
    - 자원 선점
      - 프로세스로부터 자원들을 선점하여, 이들 자원을 교착상태가 해결될 때까지 다른 프로세스들에게 할당
      - 희생자 선정, 복귀(rollback) 문제, 기아 상태 문제 등을 고려

  - 교착상태 해결 방안
    - 교착상태 예방(Prevention) : 교착상태의 필요조건을 부정함으로써 교착상태가 발생하지 않도록 미리 예방하는 방법(ex. 환형대기, 비선점, 점유와 대기, 상호배제 4가지 부정)
    - 교착상태 회피(Avoidance) : 교착상태 가능성을 배제하지 않고, 적절하게 피해 나가는 방법(ex. 은행원 알고리즘)
    - 교착상태 탐지(Detection) : 교착상태 발생을 허용하고, 발생 시 원인을 규명하여 해결하는 방법(ex. 자원 할당 그래프)
    - 교착상태 복구(Recovery) : 교착상태 발견 후 환형대기를 배제시키거나 자원을 중단하는 메모리 할당 기법(ex. 선점, 프로세스 중지(희생자 선택))

### 장치 관리 방법
***- 디스크 관리(Disk Management)***
- 디스크는 가장 많이 사용하는 보조기억장치 중 하나로 마치 레코드판을 여러 개 중첨해서 놓은 것과 비슷. 레코드판은 노래를 청취할 때 순서대로 청취해야 하지만, 디스크는 헤드(HEAD)가
임의의 섹터(Sector)를 랜덤하게 참조할 수 있고 빠르게 데이터를 읽을 수 있으며, 주기억장치보다 많은 양의 데이터를 저장가능
- `46page`
  - Arm assembly : arm을 지지하는 축
  - Spindle : platter 중앙에 회전 전달. RPM으로 속도 측정, 액세스타임과 관련
  - Arm : head가 고정되어 있는 장치
  - Head : 디스크로부터 정보를 읽어 들임
  - Sector : 디스크에 정보가 저장되는 최소 단위
  - Track : 연속된 Sector의 공간
  - Cylinder : 수직으로 연속되는 track의 집합
  - Platter : 데이터가 저장되는 자기 디스크
  - 디스크의 주소를 찾는 과정 : 디스크 번호 -> platter 번호 -> track번호 -> sector번호 -> 지정된 주소

- 디스크 접근 시간
<table border=1>
  <tr>
    <td>Disk 접근 시간</td>
    <td>설명</td>
  </tr>
  <tr>
    <td>탐색시간(Seek time)</td>
    <td>현 위치에서 특정 실린더(트랙)로 디스크 헤드가 이동하는 데 소요되는 시간</td>
  </tr>
  <tr>
    <td>회전 지연시간(Rotation delay time)</td>
    <td>가고자 하는 섹터가 디스크 헤드까지 도달하는 데 걸리는 시간</td>
  </tr>
  <tr>
    <td>전송시간(Transfer time)</td>
    <td>데이터를 전송하는 데 걸리는 시간</td>
  </tr>
</table>

- Disk Scheduling의 종류
  - FCFS(First-Come First Served)
    - 가장 먼저 도착한 요청을 우선적으로 처리
    - 장점 : 개발이 용이, 공평성 유지
    - 단점 : 이동 경로가 길어짐
  - SSTF(Shortest-Seek Time First)
    - 탐색 거리가 가장 짧은 트랙에 대한 요청을 먼저 서비스
    - 현재 Head 위치에서 가까운 요청을 우선적으로 처리
    - 장점 : 전반적인 Seek time 감소
    - 단점 : Starvation 현상 발생 가능
  - SCAN(엘리베이터 알고리즘)
    - SSTF가 갖는 탐색시간의 편차를 해소하기 위한 기법
    - Head가 이동하는 방향의 모든 요청을 서비스하고, 끝까지 이동한 후 역방향의 요청을 서비스
  - C-SCAN(Circular-SCAN)
    - 바깥쪽에서 안쪽으로 이동
    - 안쪽 방향으로 끝까지 이동을 반복
    - 끝에 도달하면 바깥쪽으로 이동하여 요청을 다시 처리
  - C-LOOK(Circular-Look)
    - C-SCAN의 보완, 대기시간을 좀 더 균형 있게 함
    - 헤드 이동 방향의 마지막 입출력 요청을 처리한 후 디스크 헤드를 처음 위치로 이동하여 다음 입출력 요청을 처리

***-파일 시스템(File System)***
- 운영체제의 중요한 기능 중 하나인 파일 시스템은 사용자가 생성한 파일을 저장소(디스크)에 어떻게 저장하고 관리할 것인지를 결정  
윈도우에서는 탐색기로 파일 시스템을 확인할 수 있으며, C:\ 폴더 아래에 여러 개의 폴더로 이루어지는 계층형(Tree 형태)구조를 가짐.  
이러한 파일 시스템에는 과거 DOS에서 사용한 FAT부터 윈도우의 NTFS, 유닉스의 UFS 등이 있음.

- FAT(File Allocation Table)
  - FAT16(File Allocation Table)
    - 대부분의 Microsoft 운영체제에서 호환되며 단순한 구조
    - 최대 2GB까지만 지원
    - 암호화 및 압축이 불가능(접근 제어 불가)
    - 파일명 최대 길이는 영문 8자
    - 클러스터당 1,632KB를 할당하여 내부 단편화가 발생

  - FAT32(File Allocation Table)
    - FAT16을 보강한 것으로, 최대 2TB까지 지원
    - 암호화 및 압축이 불가능(접근 제어 불가)
    - 파일명의 최대 길이는 256자
    - 클러스터당 4KB 사용해 내부 단편화를 줄임

  - NTFS(New Technology File System)
    - 암호화 및 압축을 지원하며, 대용량 파일 시스템을 지원
    - 가변 클러스터 크기(512~64KB)이며, 기본 값은 4KB
    - 트랜잭션 로깅을 통한 복구/오류 수정이 가능
    - Windows NT 이상에서 지원

- EXT(Extended File System)
  - EXT
    - MINIX File System을 보완하여, 최대 2GB까지 파일 시스템 크기를 지원
    - 255byte까지 파일명을 지원
    - 접근 제어, inode 수정, 타임스템프 수정 등의 기능이 불가능
    - 사용할수록 단편화가 심해짐
  - EXT2(Second Extended File System)
    - 파일 시스템은 2GB까지 지원되며, 서브 디렉터리 개수 제한이 대폭 증가
    - FSCK를 사용한 파일 시스템 오류 수정을 지원
    - 캐시의 데이터를 디스크에 저장 중 오류 발생 시 파일 시스템에 손상이 올 수 있음(Sync 이전 데이터 손실)
    - FSCK 이용한 파일 복구 시간에 많은 시간이 소요됨(전체 섹터 검사)
  - EXT3(Third Extended File System)
    - EXT2에 저널링 기능 추가 및 온라인 파일 시스템이 증대됨
    - 파일 시스템 변경 시 저널에 먼저 수정 내용을 기록(갑작스런 다운 시 빠르게 오류 복구)
    - 온라인 조각 모음이 불필요(장시간 사용 시 조각화 발생)
    - 디스크 조각화를 최소화
  - EXT4(Fourth Extended File System)
    - 16TB까지 파일 시스템을 지원하며, 볼륨은 1엑사바이트(Exabyte)까지 지원
    - Block Mapping 방식 및 Extends 방식을 지원
    - 저널 Checksum 기능이 추가되어 안전성이 강화
    - 하위 호환성 지원 : ext3, ext2와 호환 가능
    - Delayed allocation : 디스크에 쓰이기 전까지 블록 할당을 미루는 기술로 조각화 방지에 효과적
    - 온라인 조각 모음 : 조각화 방지를 위한 커널 레벨의 기술
    - Persistent pre-allocation : 파일 전체만큼의 공간을 사전 할당, 스트리밍, 데이터베이스 등에 유용

- UFS(Unix File System)의 구조
<table border=1>
  <tr>
    <td>구성 항목</td>
    <td>설명</td>
  </tr>
  <tr>
    <td>VTOC 디스크 레이블</td>
    <td>각 파티션의 기본 정보</td>
  </tr>
  <tr>
    <td>부트블록</td>
    <td>부트스트랩에 필요한 파일들</td>
  </tr>
  <tr>
    <td>프라이머리 슈퍼블록</td>
    <td>데이터 블록의 개수, 실린더 그룹의 개수, 마운트 정보</td>
  </tr>
  <tr>
    <td>백업 슈퍼블록</td>
    <td>각 실린더마다 슈퍼블록에 대한 복사본을 가짐</td>
  </tr>
  <tr>
    <td>실린더 그룹</td>
    <td>슈퍼블록, 실린더 그룹 블록, i-node 테이블, 데이터 블록을 포함</td>
  </tr>
  <tr>
    <td>슈퍼블록</td>
    <td>파일 시스템 크기, i-node 테이블의 크기, free 블록 리스트 등 파일 시스템 관리 정보</td>
  </tr>
  <tr>
    <td>실린더 그룹 블록</td>
    <td>실린더 그룹 내의 유효 블록들의 비트맵 정보나 통계 정보</td>
  </tr>
  <tr>
    <td>i-node 테이블</td>
    <td>파일에 대한 중요한 정보, 파일 크기, 위치, 유형, 사용 허가권, 날짜 정보</td>
  </tr>
  <tr>
    <td>데이터 블록</td>
    <td>실제 데이터가 저장되는 공간</td>
  </tr>
</table>

***-RAID***
- RAID는 디스크 고장 시 그대로 복구할 수 있도록 2개 이상의 디스크에 데이터를 저장하는 기술  
즉, RAID를 통해 디스크의 기계적인 장애로부터 사용자의 데이터를 안정적으로 지킬 수 있음

- RAID(Redundant Array of Independent Disks)의 개념
  - 